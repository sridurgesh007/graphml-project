{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae060190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys, Descriptors\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "os.makedirs(\"tox21_processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer=\"Raw\", data_dir=\".\", save_dir=\".\")\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e28633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset.to_dataframe()\n",
    "valid_df = valid_dataset.to_dataframe()\n",
    "test_df = test_dataset.to_dataframe()\n",
    "\n",
    "for i, task in enumerate(tasks):\n",
    "    train_df.rename(columns={f'y{i+1}': task}, inplace=True)\n",
    "    valid_df.rename(columns={f'y{i+1}': task}, inplace=True)\n",
    "    test_df.rename(columns={f'y{i+1}': task}, inplace=True)\n",
    "\n",
    "# save raw data to CSV files\n",
    "train_df.to_csv(\"tox21_processed/train_raw.csv\", index=False)\n",
    "valid_df.to_csv(\"tox21_processed/valid_raw.csv\", index=False)\n",
    "test_df.to_csv(\"tox21_processed/test_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Number of tasks: {len(tasks)}\")\n",
    "print(f\"Tasks: {tasks}\")\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(valid_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(\"Sample data:\")\n",
    "\n",
    "print(\"Data loading and initial processing complete.\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ece08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in training set:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"Missing values in validation set:\")\n",
    "print(valid_df.isnull().sum())\n",
    "print(\"Missing values in test set:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# distribution of labels for each task\n",
    "for task in tasks:\n",
    "    print(f\"Label distribution for task {task} in training set:\")\n",
    "    print(train_df[task].value_counts(dropna=False))\n",
    "    print(f\"Label distribution for task {task} in validation set:\")\n",
    "    print(valid_df[task].value_counts(dropna=False))\n",
    "    print(f\"Label distribution for task {task} in test set:\")\n",
    "    print(test_df[task].value_counts(dropna=False))\n",
    "\n",
    "# visualize some molecules\n",
    "print(\"Sample molecules from training set:\")\n",
    "for smi in train_df['ids'].head(5):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    display(Chem.Draw.MolToImage(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e62dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "def add_no_finding_label(df, tasks, label_name=\"No-finding\"):\n",
    "    task_vals = df[tasks].fillna(0).values\n",
    "    no_finding = (np.sum(task_vals, axis=1) == 0).astype(int)\n",
    "    df[label_name] = no_finding\n",
    "    print(f\" Added '{label_name}' column — {df[label_name].sum()} samples marked as 'no finding'.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_split_distribution_tox21_stacked(train_df, val_df, test_df, tasks, original_df=None, save_name=\"tox21_label_distribution_stacked.png\"):\n",
    "    def compute_ratios(df):\n",
    "        pos_ratio = []\n",
    "        neg_ratio = []\n",
    "        for t in tasks:\n",
    "            valid = df[t].notna()\n",
    "            if valid.sum() == 0:\n",
    "                pos_ratio.append(0)\n",
    "                neg_ratio.append(0)\n",
    "                continue\n",
    "            pos = df.loc[valid, t].sum()\n",
    "            total = valid.sum()\n",
    "            pos_ratio.append((pos / total) * 100)\n",
    "            neg_ratio.append(100 - (pos / total) * 100)\n",
    "        return pos_ratio, neg_ratio\n",
    "\n",
    "    train_pos, train_neg = compute_ratios(train_df)\n",
    "    val_pos, val_neg     = compute_ratios(val_df)\n",
    "    test_pos, test_neg   = compute_ratios(test_df)\n",
    "    if original_df is not None:\n",
    "        orig_pos, orig_neg = compute_ratios(original_df)\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    x = np.arange(len(tasks))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.bar(x - width*1.5, train_neg, width, label='Train (neg)', color='skyblue', alpha=0.7)\n",
    "    plt.bar(x - width*1.5, train_pos, width, bottom=train_neg, label='Train (pos)', color='blue', alpha=0.8)\n",
    "\n",
    "    plt.bar(x - width/2, val_neg, width, label='Val (neg)', color='navajowhite', alpha=0.7)\n",
    "    plt.bar(x - width/2, val_pos, width, bottom=val_neg, label='Val (pos)', color='orange', alpha=0.8)\n",
    "\n",
    "    plt.bar(x + width/2, test_neg, width, label='Test (neg)', color='palegreen', alpha=0.7)\n",
    "    plt.bar(x + width/2, test_pos, width, bottom=test_neg, label='Test (pos)', color='green', alpha=0.8)\n",
    "\n",
    "    if original_df is not None:\n",
    "        plt.bar(x + width*1.5, orig_neg, width, label='Orig (neg)', color='lightgrey', alpha=0.7)\n",
    "        plt.bar(x + width*1.5, orig_pos, width, bottom=orig_neg, label='Orig (pos)', color='grey', alpha=0.8)\n",
    "\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "    plt.title(\"Tox21 Label Distribution (Positive vs Negative Ratios per Task)\")\n",
    "    plt.xticks(x, tasks, rotation=45, ha='right')\n",
    "    plt.legend(ncol=4, bbox_to_anchor=(0.5, -0.2), loc='upper center')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    save_dir = \"imgs\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = osp.join(save_dir, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "tasks = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\",\n",
    "    \"NR-ER\", \"NR-ER-LBD\", \"NR-PPAR-gamma\",\n",
    "    \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "]\n",
    "\n",
    "train_df['split'] = 'train'\n",
    "valid_df['split'] = 'valid'\n",
    "test_df['split']  = 'test'\n",
    "\n",
    "train_df = add_no_finding_label(train_df, tasks)\n",
    "valid_df = add_no_finding_label(valid_df, tasks)\n",
    "test_df  = add_no_finding_label(test_df,  tasks)\n",
    "tasks_with_no = tasks + [\"No-finding\"]\n",
    "\n",
    "# Stack them together\n",
    "tox21_df = pd.concat([train_df, valid_df, test_df], ignore_index=True)\n",
    "cols = ['split'] + [c for c in tox21_df.columns if c != 'split']\n",
    "tox21_df = tox21_df[cols]\n",
    "\n",
    "show_split_distribution_tox21_stacked(train_df, valid_df, test_df, tasks_with_no, original_df=tox21_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0fe4a1",
   "metadata": {},
   "source": [
    "### Stratified, Round-Robin, Rare-First Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def multilabel_split_tox21(\n",
    "    df,\n",
    "    tasks,\n",
    "    train_size=20000,\n",
    "    val_size=2500,\n",
    "    test_size=2500,\n",
    "    seed=42,\n",
    "    holdout_test_df=None\n",
    "):\n",
    "    random.seed(seed)\n",
    "    df = df.reset_index(drop=True).copy()\n",
    "\n",
    "    # Exclude held-out test set\n",
    "    if holdout_test_df is not None:\n",
    "        test_df = holdout_test_df.copy()\n",
    "        heldout_idx = set(test_df.index)\n",
    "        df = df[~df.index.isin(heldout_idx)].reset_index(drop=True)\n",
    "        print(f\"Held out existing test set with {len(test_df)} samples.\")\n",
    "    else:\n",
    "        test_df = None\n",
    "\n",
    "    # Convert to numpy multilabel matrix\n",
    "    Y = df[tasks].fillna(0).astype(int).values\n",
    "    total = len(df)\n",
    "    subsz = train_size + val_size + (0 if test_df is not None else test_size)\n",
    "\n",
    "    msss = MultilabelStratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        train_size=train_size / subsz,\n",
    "        test_size=val_size / subsz,\n",
    "        random_state=seed\n",
    "    )\n",
    "    tr_i, val_i = next(msss.split(np.zeros(len(df)), Y))\n",
    "    train_df = df.iloc[tr_i].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_i].reset_index(drop=True)\n",
    "\n",
    "    if test_df is None:\n",
    "        remain = df.drop(train_df.index.union(val_df.index))\n",
    "        test_df = remain.sample(n=test_size, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Stratified Split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def multilabel_balanced_split_tox21(\n",
    "    df,\n",
    "    tasks,\n",
    "    train_size=20000,\n",
    "    val_size=2500,\n",
    "    test_size=2500,\n",
    "    seed=42,\n",
    "    holdout_test_df=None\n",
    "):\n",
    "    random.seed(seed)\n",
    "    df = df.reset_index(drop=True).copy()\n",
    "\n",
    "    if holdout_test_df is not None:\n",
    "        test_df = holdout_test_df.copy()\n",
    "        heldout_idx = set(test_df.index)\n",
    "        df = df[~df.index.isin(heldout_idx)].reset_index(drop=True)\n",
    "        print(f\"Held out fixed test set ({len(test_df)} samples).\")\n",
    "    else:\n",
    "        test_df = None\n",
    "\n",
    "    total_size = train_size + val_size + (0 if test_df is not None else test_size)\n",
    "    label2idxs = defaultdict(list)\n",
    "    \n",
    "    for task in tasks:\n",
    "        pos_idx = df.index[df[task] == 1].tolist()\n",
    "        random.shuffle(pos_idx)\n",
    "        label2idxs[task] = pos_idx\n",
    "\n",
    "    labels = list(label2idxs.keys())\n",
    "    label_ptr = {t: 0 for t in labels}\n",
    "    sampled_idx = set()\n",
    "    total_idxs = set(df.index)\n",
    "\n",
    "    # Round-robin sampling\n",
    "    while len(sampled_idx) < total_size:\n",
    "        for label in labels:\n",
    "            ptr = label_ptr[label]\n",
    "            total_label_idx = label2idxs[label]\n",
    "            if ptr >= len(total_label_idx):\n",
    "                continue\n",
    "            while ptr < len(total_label_idx):\n",
    "                xi = total_label_idx[ptr]\n",
    "                ptr += 1\n",
    "                if xi not in sampled_idx:\n",
    "                    sampled_idx.add(xi)\n",
    "                    break\n",
    "            label_ptr[label] = ptr\n",
    "        # Stop if all labels exhausted\n",
    "        if all(label_ptr[t] >= len(label2idxs[t]) for t in labels):\n",
    "            break\n",
    "\n",
    "    # Fill missing with negatives if needed\n",
    "    remaining_needed = total_size - len(sampled_idx)\n",
    "    if remaining_needed > 0:\n",
    "        remain_pool = list(total_idxs - sampled_idx)\n",
    "        random.shuffle(remain_pool)\n",
    "        sampled_idx.update(remain_pool[:remaining_needed])\n",
    "\n",
    "    sampled_idx = list(sampled_idx)\n",
    "    random.shuffle(sampled_idx)\n",
    "\n",
    "    train_ids = sampled_idx[:train_size]\n",
    "    val_ids = sampled_idx[train_size:train_size + val_size]\n",
    "\n",
    "    train_df = df.loc[train_ids].reset_index(drop=True)\n",
    "    val_df = df.loc[val_ids].reset_index(drop=True)\n",
    "\n",
    "    if test_df is None:\n",
    "        remain = df.drop(train_df.index.union(val_df.index))\n",
    "        test_df = remain.sample(n=test_size, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    print(f\" Balanced Split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def multilabel_rare_first_split_tox21(\n",
    "    df,\n",
    "    tasks,\n",
    "    train_size=20000,\n",
    "    val_size=2500,\n",
    "    test_size=2500,\n",
    "    seed=42,\n",
    "    holdout_test_df=None\n",
    "):\n",
    "    random.seed(seed)\n",
    "    df = df.reset_index(drop=True).copy()\n",
    "\n",
    "    if holdout_test_df is not None:\n",
    "        test_df = holdout_test_df.copy()\n",
    "        heldout_idx = set(test_df.index)\n",
    "        df = df[~df.index.isin(heldout_idx)].reset_index(drop=True)\n",
    "        print(f\" Held out {len(test_df)} samples for test.\")\n",
    "    else:\n",
    "        test_df = None\n",
    "\n",
    "    # Count positives per label\n",
    "    label_counts = {t: int(df[t].fillna(0).sum()) for t in tasks}\n",
    "    sorted_labels = sorted(label_counts.items(), key=lambda x: x[1])  # rare  common\n",
    "\n",
    "    # Build mapping of task  indices with label == 1\n",
    "    label2idxs = {t: df.index[df[t] == 1].tolist() for t in tasks}\n",
    "    for idx_list in label2idxs.values():\n",
    "        random.shuffle(idx_list)\n",
    "\n",
    "    train_idx, val_idx, used_idx = set(), set(), set()\n",
    "    total_needed = train_size + val_size + (0 if test_df is not None else test_size)\n",
    "\n",
    "    for task, _ in sorted_labels:\n",
    "        available = [i for i in label2idxs[task] if i not in used_idx]\n",
    "        random.shuffle(available)\n",
    "        for i in available:\n",
    "            if len(train_idx) < train_size:\n",
    "                train_idx.add(i)\n",
    "            elif len(val_idx) < val_size:\n",
    "                val_idx.add(i)\n",
    "            used_idx.add(i)\n",
    "            if len(train_idx) + len(val_idx) >= total_needed:\n",
    "                break\n",
    "        if len(train_idx) + len(val_idx) >= total_needed:\n",
    "            break\n",
    "\n",
    "    # Fill remaining from unassigned samples\n",
    "    remaining = list(set(df.index) - used_idx)\n",
    "    random.shuffle(remaining)\n",
    "    for i in remaining:\n",
    "        if len(train_idx) < train_size:\n",
    "            train_idx.add(i)\n",
    "        elif len(val_idx) < val_size:\n",
    "            val_idx.add(i)\n",
    "\n",
    "    train_df = df.loc[list(train_idx)].reset_index(drop=True)\n",
    "    val_df = df.loc[list(val_idx)].reset_index(drop=True)\n",
    "\n",
    "    if test_df is None:\n",
    "        remain = list(set(df.index) - train_idx - val_idx)\n",
    "        random.shuffle(remain)\n",
    "        test_df = df.loc[remain[:test_size]].reset_index(drop=True)\n",
    "\n",
    "    print(f\" Rare-first Split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "strat_train_df, strat_valid_df, strat_test_df=  multilabel_split_tox21(tox21_df, tasks_with_no, len(train_df), len(valid_df), len(test_df), holdout_test_df=test_df)\n",
    "bal_train_df, bal_valid_df, bal_test_df=  multilabel_balanced_split_tox21(tox21_df,tasks_with_no, len(train_df), len(valid_df), len(test_df), holdout_test_df=test_df)\n",
    "rare_train_df, rare_valid_df, rare_test_df=  multilabel_rare_first_split_tox21(tox21_df,tasks_with_no, len(train_df), len(valid_df), len(test_df), holdout_test_df=test_df)\n",
    "\n",
    "show_split_distribution_tox21_stacked(strat_train_df, strat_valid_df, strat_test_df, tasks_with_no, original_df=tox21_df)\n",
    "show_split_distribution_tox21_stacked(bal_train_df, bal_valid_df, bal_test_df, tasks_with_no, original_df=tox21_df)\n",
    "show_split_distribution_tox21_stacked(rare_train_df, rare_valid_df, rare_test_df, tasks_with_no, original_df=tox21_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb393a3",
   "metadata": {},
   "source": [
    "### Extract molecular features for training basic machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e541e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract molecular features using RDKit and save to CSV files\n",
    "def featurize_molecule(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    features = {}\n",
    "    # Basic descriptors\n",
    "    features['MolWt'] = Descriptors.MolWt(mol)\n",
    "    features['NumHDonors'] = Descriptors.NumHDonors(mol)\n",
    "    features['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)\n",
    "    features['TPSA'] = Descriptors.TPSA(mol)\n",
    "    features['LogP'] = Descriptors.MolLogP(mol)\n",
    "    # MACCS keys\n",
    "    maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "    for i in range(167):\n",
    "        features[f'MACCS_{i}'] = int(maccs.GetBit(i))\n",
    "    # Morgan fingerprint\n",
    "    morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)\n",
    "    for i in range(2048):\n",
    "        features[f'Morgan_{i}'] = int(morgan_fp.GetBit(i))\n",
    "    return features\n",
    "\n",
    "def featurize_dataset(df):\n",
    "    feature_list = []\n",
    "    for smi in tqdm(df['ids'], desc=\"Featurizing molecules\"):\n",
    "        feats = featurize_molecule(smi)\n",
    "        if feats is not None:\n",
    "            feature_list.append(feats)\n",
    "        else:\n",
    "            feature_list.append({})\n",
    "    features_df = pd.DataFrame(feature_list)\n",
    "    return pd.concat([df.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "train_features_df = featurize_dataset(train_df)\n",
    "valid_features_df = featurize_dataset(valid_df)\n",
    "test_features_df = featurize_dataset(test_df)\n",
    "\n",
    "strat_feat_train_df, strat_feat_valid_df, strat_feat_test_df=  featurize_dataset(strat_train_df), featurize_dataset(strat_valid_df), featurize_dataset(strat_test_df)\n",
    "bal_feat_train_df, bal_feat_valid_df, bal_feat_test_df=  featurize_dataset(bal_train_df), featurize_dataset(bal_valid_df), featurize_dataset(bal_test_df)\n",
    "rare_feat_train_df, rare_feat_valid_df, rare_feat_test_df=   featurize_dataset(rare_train_df), featurize_dataset(rare_valid_df), featurize_dataset(rare_test_df)\n",
    "\n",
    "\n",
    "train_features_df.to_csv(\"tox21_processed/train_featurized.csv\", index=False)\n",
    "valid_features_df.to_csv(\"tox21_processed/valid_featurized.csv\", index=False)   \n",
    "test_features_df.to_csv(\"tox21_processed/test_featurized.csv\", index=False)\n",
    "\n",
    "strat_feat_train_df.to_csv(\"tox21_processed/strat_feat_train_df.csv\", index=False)\n",
    "strat_feat_valid_df.to_csv(\"tox21_processed/strat_feat_valid_df.csv\", index=False)   \n",
    "strat_feat_test_df.to_csv(\"tox21_processed/strat_feat_test_df.csv\", index=False)\n",
    "\n",
    "bal_feat_train_df.to_csv(\"tox21_processed/bal_feat_train_df.csv\", index=False)\n",
    "bal_feat_valid_df.to_csv(\"tox21_processed/bal_feat_valid_df.csv\", index=False)   \n",
    "bal_feat_test_df.to_csv(\"tox21_processed/bal_feat_test_df.csv\", index=False)\n",
    "\n",
    "rare_feat_train_df.to_csv(\"tox21_processed/rare_feat_train_df.csv\", index=False)\n",
    "rare_feat_valid_df.to_csv(\"tox21_processed/rare_feat_valid_df.csv\", index=False)   \n",
    "rare_feat_test_df.to_csv(\"tox21_processed/rare_feat_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new dataframes\n",
    "print(\"Featurized training set sample:\")\n",
    "train_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124aa716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Featurized training set info:\")\n",
    "print(train_features_df.info())\n",
    "print(\"Featurized validation set info:\")\n",
    "print(valid_features_df.info())\n",
    "print(\"Featurized test set info:\")\n",
    "print(test_features_df.info())\n",
    "print(\" Featurization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the object type columns to verify\n",
    "print(train_features_df.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for any remaining missing values\n",
    "print(\"Missing values in featurized training set:\")\n",
    "print(train_features_df.isnull().sum().sum())\n",
    "print(\"Missing values in featurized validation set:\")\n",
    "print(valid_features_df.isnull().sum().sum())\n",
    "print(\"Missing values in featurized test set:\")\n",
    "print(test_features_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fe8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "continuous_features = ['MolWt', 'NumHDonors', 'NumHAcceptors', 'TPSA', 'LogP']\n",
    "scaler = StandardScaler()\n",
    "train_features_df[continuous_features] = scaler.fit_transform(train_features_df[continuous_features])\n",
    "valid_features_df[continuous_features] = scaler.transform(valid_features_df[continuous_features])\n",
    "test_features_df[continuous_features] = scaler.transform(test_features_df[continuous_features])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "strat_feat_train_df[continuous_features] , strat_feat_valid_df[continuous_features] , strat_feat_test_df[continuous_features] =  scaler.fit_transform(strat_feat_train_df[continuous_features]), scaler.transform(strat_feat_valid_df[continuous_features]),   scaler.transform(strat_feat_test_df[continuous_features])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bal_feat_train_df[continuous_features] , bal_feat_valid_df[continuous_features] , bal_feat_test_df[continuous_features] = scaler.fit_transform(bal_feat_train_df[continuous_features]), scaler.transform(bal_feat_valid_df[continuous_features]),   scaler.transform(bal_feat_test_df[continuous_features])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rare_feat_train_df[continuous_features] , rare_feat_valid_df[continuous_features] , rare_feat_test_df[continuous_features] =  scaler.fit_transform(rare_feat_train_df[continuous_features]), scaler.transform(rare_feat_valid_df[continuous_features]),   scaler.transform(rare_feat_test_df[continuous_features])\n",
    "\n",
    "\n",
    "print(\"Normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normalized data to CSV files\n",
    "train_features_df.to_csv(\"tox21_processed/train_normalized.csv\", index=False)\n",
    "valid_features_df.to_csv(\"tox21_processed/valid_normalized.csv\", index=False)\n",
    "test_features_df.to_csv(\"tox21_processed/test_normalized.csv\", index=False)\n",
    "\n",
    "\n",
    "strat_feat_train_df.to_csv(\"tox21_processed/strat_normalized_train_df.csv\", index=False)\n",
    "strat_feat_valid_df.to_csv(\"tox21_processed/strat_normalized_valid_df.csv\", index=False)   \n",
    "strat_feat_test_df.to_csv(\"tox21_processed/strat_normalized_test_df.csv\", index=False)\n",
    "\n",
    "bal_feat_train_df.to_csv(\"tox21_processed/bal_normalized_train_df.csv\", index=False)\n",
    "bal_feat_valid_df.to_csv(\"tox21_processed/bal_normalized_valid_df.csv\", index=False)   \n",
    "bal_feat_test_df.to_csv(\"tox21_processed/bal_normalized_test_df.csv\", index=False)\n",
    "\n",
    "rare_feat_train_df.to_csv(\"tox21_processed/rare_normalized_train_df.csv\", index=False)\n",
    "rare_feat_valid_df.to_csv(\"tox21_processed/rare_normalized_valid_df.csv\", index=False)   \n",
    "rare_feat_test_df.to_csv(\"tox21_processed/rare_normalized_test_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e307ee",
   "metadata": {},
   "source": [
    "### Extract graph features for training graph machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import torch\n",
    "\n",
    "# convert data to graph format for graph neural networks\n",
    "def mol_to_graph_data_obj(mol, df, tasks=tasks):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    # node features\n",
    "    atom_features_list = []\n",
    "\n",
    "    # ensure molecule has 3D conformer\n",
    "    if mol.GetNumConformers() == 0:\n",
    "        mol = Chem.AddHs(mol)\n",
    "        AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
    "        AllChem.UFFOptimizeMolecule(mol)\n",
    "    conf = mol.GetConformer()\n",
    "    coords = [] \n",
    "    for atom in mol.GetAtoms():\n",
    "        pos = conf.GetAtomPosition(atom.GetIdx())\n",
    "        coords.append([pos.x, pos.y, pos.z])\n",
    "    pos = torch.tensor(coords, dtype=torch.float)\n",
    "\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features = []\n",
    "        atom_features.append(atom.GetAtomicNum())\n",
    "        atom_features.append(atom.GetDegree())\n",
    "        atom_features.append(atom.GetFormalCharge())\n",
    "        atom_features.append(atom.GetHybridization())\n",
    "        atom_features.append(int(atom.GetIsAromatic()))\n",
    "        atom_features_list.append(atom_features)\n",
    "\n",
    "    # standardize node features to tensor\n",
    "    x = torch.tensor(atom_features_list, dtype=torch.float)\n",
    "\n",
    "    # edge index and edge features\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.append((i, j))\n",
    "        edge_index.append((j, i))\n",
    "        bond_type = bond.GetBondType()\n",
    "        if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "            edge_attr.append([1, 0, 0])\n",
    "            edge_attr.append([1, 0, 0])\n",
    "        elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "            edge_attr.append([0, 1, 0])\n",
    "            edge_attr.append([0, 1, 0])\n",
    "        elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "            edge_attr.append([0, 0, 1])\n",
    "            edge_attr.append([0, 0, 1])\n",
    "        else:\n",
    "            edge_attr.append([0, 0, 0])\n",
    "            edge_attr.append([0, 0, 0])\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 3), dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,pos=pos)\n",
    "    \n",
    "    smi = Chem.MolToSmiles(mol)\n",
    "    labels = df[df['ids'] == smi][tasks].values\n",
    "    if len(labels) > 0:\n",
    "        data.y = torch.tensor(labels[0], dtype=torch.float)\n",
    "    else:\n",
    "        data.y = torch.tensor([float('nan')] * len(tasks), dtype=torch.float)\n",
    "\n",
    "    return data\n",
    "\n",
    "def featurize_graph_dataset(df, tasks=tasks):\n",
    "    graph_list = []\n",
    "    for smi in tqdm(df['ids'], desc=\"Featurizing molecules to graphs\"):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        graph = mol_to_graph_data_obj(mol, df, tasks=tasks)\n",
    "\n",
    "        # get label row for this molecule\n",
    "        row = df[df['ids'] == smi][tasks].values\n",
    "        if len(row) == 0:\n",
    "            continue\n",
    "        row = row[0]\n",
    "\n",
    "        graph_list.append(graph)\n",
    "    return graph_list\n",
    "\n",
    "train_graphs = featurize_graph_dataset(train_df)\n",
    "valid_graphs = featurize_graph_dataset(valid_df)\n",
    "test_graphs = featurize_graph_dataset(test_df)\n",
    "\n",
    "strat_train_graphs = featurize_graph_dataset(strat_feat_train_df, tasks = tasks_with_no)\n",
    "strat_valid_graphs = featurize_graph_dataset(strat_feat_valid_df, tasks = tasks_with_no)\n",
    "strat_test_graphs = featurize_graph_dataset(strat_feat_test_df, tasks = tasks_with_no)\n",
    "\n",
    "bal_train_graphs = featurize_graph_dataset(bal_train_df, tasks = tasks_with_no)\n",
    "bal_valid_graphs = featurize_graph_dataset(bal_valid_df, tasks = tasks_with_no)\n",
    "bal_test_graphs = featurize_graph_dataset(bal_test_df, tasks = tasks_with_no)\n",
    "\n",
    "rare_train_graphs = featurize_graph_dataset(rare_train_df, tasks = tasks_with_no)\n",
    "rare_valid_graphs = featurize_graph_dataset(rare_valid_df, tasks = tasks_with_no)\n",
    "rare_test_graphs = featurize_graph_dataset(rare_test_df, tasks = tasks_with_no)\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_graphs)}\")\n",
    "print(f\"Number of validation graphs: {len(valid_graphs)}\")\n",
    "print(f\"Number of test graphs: {len(test_graphs)}\")\n",
    "print(\"Sample graph data object:\")\n",
    "print(train_graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d64dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_graphs[138].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import torch\n",
    "\n",
    "# pick one molecule and its graph\n",
    "idx = 138\n",
    "mol = Chem.MolFromSmiles(train_df['ids'].iloc[idx])\n",
    "graph = train_graphs[idx]\n",
    "\n",
    "# extract label\n",
    "label_value = graph.y.item() if graph.y.numel() == 1 else graph.y.tolist()\n",
    "print(\"Label(s):\", label_value)\n",
    "\n",
    "# draw with RDKit\n",
    "img = Draw.MolToImage(mol, size=(300, 300), legend=f\"Label: {label_value}\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_graph_by_label(data, title_prefix=\"Graph\"):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "    # get label\n",
    "    if data.y.numel() == 1:\n",
    "        label = data.y.item()\n",
    "    else:\n",
    "        label = data.y.tolist()\n",
    "\n",
    "    # choose color based on label\n",
    "    if isinstance(label, (int, float)):\n",
    "        color = \"red\" if label > 0.5 else \"blue\"  # binary coloring\n",
    "    else:\n",
    "        color = \"gray\"\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    nx.draw(\n",
    "        G,\n",
    "        with_labels=True,\n",
    "        node_color=color,\n",
    "        edge_color=\"gray\",\n",
    "        node_size=600,\n",
    "        font_weight=\"bold\",\n",
    "    )\n",
    "    plt.title(f\"{title_prefix} | Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Example\n",
    "visualize_graph_by_label(train_graphs[138], title_prefix=\"Training Graph 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d168c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs[138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cae032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph data objects using torch.save\n",
    "torch.save(train_graphs, \"tox21_processed/train_graphs.pt\")\n",
    "torch.save(valid_graphs, \"tox21_processed/valid_graphs.pt\")\n",
    "torch.save(test_graphs, \"tox21_processed/test_graphs.pt\")\n",
    "\n",
    "torch.save(strat_train_graphs, \"tox21_processed/strat_train_graphs.pt\")\n",
    "torch.save(strat_valid_graphs, \"tox21_processed/strat_valid_graphs.pt\")\n",
    "torch.save(strat_test_graphs, \"tox21_processed/strat_test_graphs.pt\")\n",
    "\n",
    "torch.save(bal_train_graphs, \"tox21_processed/bal_train_graphs.pt\")\n",
    "torch.save(bal_valid_graphs, \"tox21_processed/bal_valid_graphs.pt\")\n",
    "torch.save(bal_test_graphs, \"tox21_processed/bal_test_graphs.pt\")\n",
    "\n",
    "torch.save(rare_train_graphs, \"tox21_processed/rare_train_graphs.pt\")\n",
    "torch.save(rare_valid_graphs, \"tox21_processed/rare_valid_graphs.pt\")\n",
    "torch.save(rare_test_graphs, \"tox21_processed/rare_test_graphs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(\n",
    "    featurizer=\"Raw\", data_dir=\".\", save_dir=\".\"\n",
    ")\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "# Convert to pandas DataFrames\n",
    "train_df = train_dataset.to_dataframe()\n",
    "valid_df = valid_dataset.to_dataframe()\n",
    "test_df = test_dataset.to_dataframe()\n",
    "\n",
    "# Combine all Mol objects\n",
    "all_mols = list(train_df[\"X\"]) + list(valid_df[\"X\"]) + list(test_df[\"X\"])\n",
    "\n",
    "# Count atom occurrences\n",
    "atom_counter = Counter()\n",
    "for mol in all_mols:\n",
    "    if mol is None:\n",
    "        continue\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        if symbol != \"H\": \n",
    "            atom_counter[symbol] += 1\n",
    "\n",
    "# Sort by frequency\n",
    "atoms, counts = zip(*sorted(atom_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(atoms, counts, color='skyblue')\n",
    "plt.xlabel(\"Atom Type\", fontsize=12)\n",
    "plt.ylabel(\"Total Count (Train + Valid + Test)\", fontsize=12)\n",
    "plt.title(\"Tox21 Atom Type Frequency\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "rare_atoms = {\n",
    "    \"Br\", \"I\", \"Si\", \"B\", \"Se\", \"Sn\", \"Te\", \"Zr\", \"Cr\", \"V\", \"Ti\",\n",
    "    \"Ge\", \"As\", \"Cu\", \"Zn\", \"Pd\", \"Ru\", \"Pt\", \"Mn\", \"Ni\", \"Co\",\n",
    "    \"Na\", \"K\", \"Ca\", \"Mg\", \"Li\", \"Al\", \"Bi\", \"Sb\", \"Hg\", \"Pb\"\n",
    "}\n",
    "\n",
    "def has_rare_atoms(mol):\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return any(atom.GetSymbol() in rare_atoms for atom in mol.GetAtoms())\n",
    "\n",
    "# Combine all Mol objects again\n",
    "all_mols = list(train_df[\"X\"]) + list(valid_df[\"X\"]) + list(test_df[\"X\"])\n",
    "\n",
    "# Count how many contain any rare atom\n",
    "rare_count = sum(has_rare_atoms(mol) for mol in all_mols)\n",
    "total_count = len(all_mols)\n",
    "\n",
    "print(f\"Total molecules: {total_count}\")\n",
    "print(f\"Molecules with Br or rarer atoms: {rare_count}\")\n",
    "print(f\"Fraction: {rare_count/total_count:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37137612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "rare_atoms = {\n",
    "    \"Br\", \"I\", \"Si\", \"B\", \"Se\", \"Sn\", \"Te\", \"Zr\", \"Cr\", \"V\", \"Ti\",\n",
    "    \"Ge\", \"As\", \"Cu\", \"Zn\", \"Pd\", \"Ru\", \"Pt\", \"Mn\", \"Ni\", \"Co\",\n",
    "    \"Na\", \"K\", \"Ca\", \"Mg\", \"Li\", \"Al\", \"Bi\", \"Sb\", \"Hg\", \"Pb\"\n",
    "}\n",
    "\n",
    "def has_rare_atoms(mol):\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return any(atom.GetSymbol() in rare_atoms for atom in mol.GetAtoms())\n",
    "\n",
    "# Combine train/valid/test\n",
    "all_df = pd.concat([\n",
    "    train_dataset.to_dataframe(),\n",
    "    valid_dataset.to_dataframe(),\n",
    "    test_dataset.to_dataframe()\n",
    "], ignore_index=True)\n",
    "\n",
    "# Extract relevant columns\n",
    "y_cols = [c for c in all_df.columns if c.startswith(\"y\")]\n",
    "mols = list(all_df[\"X\"])\n",
    "y = all_df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "\n",
    "# Filter out molecules with rare atoms\n",
    "rare_mask = np.array([has_rare_atoms(m) for m in mols])\n",
    "filtered_y = y[~rare_mask]\n",
    "\n",
    "# Identify \"no finding\" (all zeros or NaNs)\n",
    "is_no_finding = np.all((np.isnan(filtered_y)) | (filtered_y == 0), axis=1)\n",
    "\n",
    "# Print summary\n",
    "total = len(filtered_y)\n",
    "no_findings = np.sum(is_no_finding)\n",
    "print(f\"Total molecules (without rare atoms): {total}\")\n",
    "print(f\"'No-finding' molecules (all y* = 0 or NaN): {no_findings}\")\n",
    "print(f\"Fraction: {no_findings/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rare_atoms = {\n",
    "    \"Br\", \"I\", \"Si\", \"B\", \"Se\", \"Sn\", \"Te\", \"Zr\", \"Cr\", \"V\", \"Ti\",\n",
    "    \"Ge\", \"As\", \"Cu\", \"Zn\", \"Pd\", \"Ru\", \"Pt\", \"Mn\", \"Ni\", \"Co\",\n",
    "    \"Na\", \"K\", \"Ca\", \"Mg\", \"Li\", \"Al\", \"Bi\", \"Sb\", \"Hg\", \"Pb\"\n",
    "}\n",
    "\n",
    "def has_rare_atoms(mol):\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return any(atom.GetSymbol() in rare_atoms for atom in mol.GetAtoms())\n",
    "\n",
    "def compute_split_stats(dataset, split_name):\n",
    "    \"\"\"Return stats for one split.\"\"\"\n",
    "    df = dataset.to_dataframe()\n",
    "    mols = list(df[\"X\"])\n",
    "    y_cols = [c for c in df.columns if c.startswith(\"y\")]\n",
    "    y = df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "\n",
    "    # rare-atom mask\n",
    "    rare_mask = np.array([has_rare_atoms(m) for m in mols])\n",
    "\n",
    "    # filter out rare atoms\n",
    "    filtered_y = y[~rare_mask]\n",
    "\n",
    "    # molecules with no findings (all y* = 0 or NaN)\n",
    "    is_no_finding = np.all((np.isnan(filtered_y)) | (filtered_y == 0), axis=1)\n",
    "\n",
    "    total = len(filtered_y)\n",
    "    no_findings = np.sum(is_no_finding)\n",
    "    print(f\"=== {split_name.upper()} SPLIT ===\")\n",
    "    print(f\"Total molecules (no rare atoms): {total}\")\n",
    "    print(f\"'No-finding' molecules: {no_findings}\")\n",
    "    print(f\"Fraction: {no_findings/total:.3f}\\n\")\n",
    "\n",
    "# ---- Run for each split ----\n",
    "compute_split_stats(train_dataset, \"train\")\n",
    "compute_split_stats(valid_dataset, \"valid\")\n",
    "compute_split_stats(test_dataset, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "\n",
    "rare_atoms = {\n",
    "    \"Br\", \"I\", \"Si\", \"B\", \"Se\", \"Sn\", \"Te\", \"Zr\", \"Cr\", \"V\", \"Ti\",\n",
    "    \"Ge\", \"As\", \"Cu\", \"Zn\", \"Pd\", \"Ru\", \"Pt\", \"Mn\", \"Ni\", \"Co\",\n",
    "    \"Na\", \"K\", \"Ca\", \"Mg\", \"Li\", \"Al\", \"Bi\", \"Sb\", \"Hg\", \"Pb\"\n",
    "}\n",
    "\n",
    "def has_rare_atoms(mol):\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return any(atom.GetSymbol() in rare_atoms for atom in mol.GetAtoms())\n",
    "\n",
    "def label_distribution(dataset, split_name):\n",
    "    df = dataset.to_dataframe()\n",
    "    mols = list(df[\"X\"])\n",
    "    y_cols = [c for c in df.columns if c.startswith(\"y\")]\n",
    "    y = df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "\n",
    "    # remove rare-atom molecules\n",
    "    rare_mask = np.array([has_rare_atoms(m) for m in mols])\n",
    "    filtered_y = y[~rare_mask]\n",
    "\n",
    "    # keep only molecules with at least one positive finding\n",
    "    has_finding = np.any(filtered_y == 1, axis=1)\n",
    "    y_with_findings = filtered_y[has_finding]\n",
    "\n",
    "    # compute per-label positive counts\n",
    "    pos_counts = np.nansum(y_with_findings == 1, axis=0)\n",
    "    total = len(y_with_findings)\n",
    "    fractions = pos_counts / total\n",
    "\n",
    "    print(f\"=== {split_name.upper()} SPLIT ===\")\n",
    "    print(f\"Molecules with findings (no rare atoms): {total}\")\n",
    "    print(pd.DataFrame({'Assay': y_cols, 'Positives': pos_counts, 'Fraction': fractions}))\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(y_cols, fractions, color=\"mediumseagreen\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Fraction positive\")\n",
    "    plt.title(f\"{split_name.title()} Split – Label Distribution (with findings, no rare atoms)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run for each split\n",
    "label_distribution(train_dataset, \"train\")\n",
    "label_distribution(valid_dataset, \"valid\")\n",
    "label_distribution(test_dataset, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d82642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "def molecule_length(mol):\n",
    "    if mol is None:\n",
    "        return np.nan\n",
    "    return sum(atom.GetSymbol() != \"H\" for atom in mol.GetAtoms())\n",
    "\n",
    "def plot_molecule_length_distribution(dataset, split_name):\n",
    "    df = dataset.to_dataframe()\n",
    "    mols = list(df[\"X\"])\n",
    "\n",
    "    lengths = [molecule_length(m) for m in mols if m is not None]\n",
    "    lengths = np.array(lengths, dtype=float)\n",
    "    mean_len, median_len = np.nanmean(lengths), np.nanmedian(lengths)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(lengths, bins=25, color=\"cornflowerblue\", edgecolor=\"black\", alpha=0.75)\n",
    "    plt.title(f\"{split_name.title()} Split Molecule Length Distribution\", fontsize=13)\n",
    "    plt.xlabel(\"Number of heavy atoms (no H)\", fontsize=11)\n",
    "    plt.ylabel(\"Count\", fontsize=11)\n",
    "    plt.axvline(mean_len, color=\"red\", linestyle=\"--\", label=f\"Mean = {mean_len:.1f}\")\n",
    "    plt.axvline(median_len, color=\"orange\", linestyle=\":\", label=f\"Median = {median_len:.1f}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"{split_name.title()} split  mean length: {mean_len:.2f}, median: {median_len:.2f}, \"\n",
    "          f\"min: {np.nanmin(lengths)}, max: {np.nanmax(lengths)}\")\n",
    "\n",
    "# Run for each split\n",
    "plot_molecule_length_distribution(train_dataset, \"train\")\n",
    "plot_molecule_length_distribution(valid_dataset, \"valid\")\n",
    "plot_molecule_length_distribution(test_dataset, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a565471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "def molecule_edges(mol):\n",
    "    if mol is None:\n",
    "        return np.nan\n",
    "    return mol.GetNumBonds()\n",
    "\n",
    "def plot_edge_distribution(dataset, split_name):\n",
    "    df = dataset.to_dataframe()\n",
    "    mols = list(df[\"X\"])\n",
    "\n",
    "    edges = [molecule_edges(m) for m in mols if m is not None]\n",
    "    edges = np.array(edges, dtype=float)\n",
    "\n",
    "    mean_edges, median_edges = np.nanmean(edges), np.nanmedian(edges)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(edges, bins=25, color=\"lightcoral\", edgecolor=\"black\", alpha=0.75)\n",
    "    plt.title(f\"{split_name.title()} Split Edge (Bond) Count Distribution\", fontsize=13)\n",
    "    plt.xlabel(\"Number of bonds (edges)\", fontsize=11)\n",
    "    plt.ylabel(\"Count\", fontsize=11)\n",
    "    plt.axvline(mean_edges, color=\"red\", linestyle=\"--\", label=f\"Mean = {mean_edges:.1f}\")\n",
    "    plt.axvline(median_edges, color=\"orange\", linestyle=\":\", label=f\"Median = {median_edges:.1f}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"{split_name.title()} split mean edges: {mean_edges:.2f}, \"\n",
    "          f\"median: {median_edges:.2f}, min: {np.nanmin(edges)}, max: {np.nanmax(edges)}\")\n",
    "\n",
    "\n",
    "plot_edge_distribution(train_dataset, \"train\")\n",
    "plot_edge_distribution(valid_dataset, \"valid\")\n",
    "plot_edge_distribution(test_dataset, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "rare_atoms = {\n",
    "    \"Br\", \"I\", \"Si\", \"B\", \"Se\", \"Sn\", \"Te\", \"Zr\", \"Cr\", \"V\", \"Ti\",\n",
    "    \"Ge\", \"As\", \"Cu\", \"Zn\", \"Pd\", \"Ru\", \"Pt\", \"Mn\", \"Ni\", \"Co\",\n",
    "    \"Na\", \"K\", \"Ca\", \"Mg\", \"Li\", \"Al\", \"Bi\", \"Sb\", \"Hg\", \"Pb\"\n",
    "}\n",
    "\n",
    "def has_rare_atoms(mol):\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return any(atom.GetSymbol() in rare_atoms for atom in mol.GetAtoms())\n",
    "\n",
    "def molecule_length(mol):\n",
    "    if mol is None:\n",
    "        return np.nan\n",
    "    return sum(atom.GetSymbol() != \"H\" for atom in mol.GetAtoms())\n",
    "\n",
    "def molecule_edges(mol):\n",
    "    if mol is None:\n",
    "        return np.nan\n",
    "    return mol.GetNumBonds()\n",
    "\n",
    "def filter_and_plot(dataset, split_name):\n",
    "    df = dataset.to_dataframe()\n",
    "    mols = list(df[\"X\"])\n",
    "    y_cols = [c for c in df.columns if c.startswith(\"y\")]\n",
    "    y = df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "\n",
    "    rare_mask = np.array([has_rare_atoms(m) for m in mols])\n",
    "    mols_filtered = [m for m, rare in zip(mols, rare_mask) if not rare]\n",
    "    y_filtered = y[~rare_mask]\n",
    "\n",
    "\n",
    "    has_finding = np.any(y_filtered == 1, axis=1)\n",
    "    mols_final = [m for m, keep in zip(mols_filtered, has_finding) if keep]\n",
    "    y_final = y_filtered[has_finding]\n",
    "\n",
    "    # Compute molecule length and edge counts\n",
    "    lengths = np.array([molecule_length(m) for m in mols_final if m is not None], dtype=float)\n",
    "    edges   = np.array([molecule_edges(m) for m in mols_final if m is not None], dtype=float)\n",
    "\n",
    "    print(f\"=== {split_name.upper()} SPLIT ===\")\n",
    "    print(f\"Molecules after filtering: {len(mols_final)}\")\n",
    "    print(f\"Mean length: {np.nanmean(lengths):.2f}, edges: {np.nanmean(edges):.2f}\")\n",
    "    print(f\"Median length: {np.nanmedian(lengths):.2f}, edges: {np.nanmedian(edges):.2f}\\n\")\n",
    "\n",
    "    # Plot molecule length\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(lengths, bins=25, color=\"steelblue\", edgecolor=\"black\", alpha=0.75)\n",
    "    plt.title(f\"{split_name.title()} – Molecule Length (no rare atoms, with findings)\", fontsize=13)\n",
    "    plt.xlabel(\"Number of heavy atoms\", fontsize=11)\n",
    "    plt.ylabel(\"Count\", fontsize=11)\n",
    "    plt.axvline(np.nanmean(lengths), color=\"red\", linestyle=\"--\", label=f\"Mean = {np.nanmean(lengths):.1f}\")\n",
    "    plt.axvline(np.nanmedian(lengths), color=\"orange\", linestyle=\":\", label=f\"Median = {np.nanmedian(lengths):.1f}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot edge count \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(edges, bins=25, color=\"salmon\", edgecolor=\"black\", alpha=0.75)\n",
    "    plt.title(f\"{split_name.title()} – Edge Count (no rare atoms, with findings)\", fontsize=13)\n",
    "    plt.xlabel(\"Number of bonds\", fontsize=11)\n",
    "    plt.ylabel(\"Count\", fontsize=11)\n",
    "    plt.axvline(np.nanmean(edges), color=\"red\", linestyle=\"--\", label=f\"Mean = {np.nanmean(edges):.1f}\")\n",
    "    plt.axvline(np.nanmedian(edges), color=\"orange\", linestyle=\":\", label=f\"Median = {np.nanmedian(edges):.1f}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "filter_and_plot(train_dataset, \"train\")\n",
    "filter_and_plot(valid_dataset, \"valid\")\n",
    "filter_and_plot(test_dataset, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_12xagon_scatter(df, exclude_no_finding=True, n_samples=None):\n",
    "    task_names = [\n",
    "        \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\",\n",
    "        \"NR-ER\", \"NR-ER-LBD\", \"NR-PPAR-γ\",\n",
    "        \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    y_cols = [c for c in df.columns if c.startswith(\"y\")]\n",
    "    y = df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "\n",
    "    if exclude_no_finding:\n",
    "        mask = ~np.all((np.isnan(y)) | (y == 0), axis=1)\n",
    "        y = y[mask]\n",
    "\n",
    "\n",
    "        idx = np.random.choice(len(y), size=min(n_samples, len(y)), replace=False)\n",
    "        y = y[idx]\n",
    "\n",
    "    y = np.nan_to_num(y, nan=0)\n",
    "\n",
    "    # Compute 12-gon vertex directions\n",
    "    N = y.shape[1]\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False)\n",
    "\n",
    "\n",
    "    x_coords, y_coords = [], []\n",
    "    for yi in y:\n",
    "        if yi.sum() == 0:\n",
    "            continue\n",
    "        weights = yi / yi.sum()\n",
    "        x = np.sum(weights * np.cos(angles))\n",
    "        y_ = np.sum(weights * np.sin(angles))\n",
    "        x_coords.append(x)\n",
    "        y_coords.append(y_)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(\n",
    "        x_coords, y_coords, s=20, alpha=0.6,\n",
    "        color='mediumseagreen', edgecolors='black', linewidths=0.4\n",
    "    )\n",
    "    plt.title(\"Tox21 12-Label Dodecagon Scatter (molecules with findings only)\", fontsize=13)\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    # Draw 12-gon boundary\n",
    "    boundary_x = np.cos(angles).tolist() + [np.cos(angles[0])]\n",
    "    boundary_y = np.sin(angles).tolist() + [np.sin(angles[0])]\n",
    "    plt.plot(boundary_x, boundary_y, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Label vertices using actual task names\n",
    "    for i, (bx, by) in enumerate(zip(boundary_x[:-1], boundary_y[:-1])):\n",
    "        plt.text(1.15*bx, 1.15*by, task_names[i], ha='center', va='center', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "train_df = train_dataset.to_dataframe()\n",
    "plot_12xagon_scatter(train_df, exclude_no_finding=True, n_samples=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "def plot_12xagon_3d_frequency(df, exclude_no_finding=True, bins=40):\n",
    "    task_names = [\n",
    "        \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\",\n",
    "        \"NR-ER\", \"NR-ER-LBD\", \"NR-PPAR-γ\",\n",
    "        \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    y_cols = [c for c in df.columns if c.startswith(\"y\")]\n",
    "    y = df[y_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float32)\n",
    "    y = np.nan_to_num(y, nan=0)\n",
    "\n",
    "\n",
    "    if exclude_no_finding:\n",
    "        mask = ~np.all(y == 0, axis=1)\n",
    "        y = y[mask]\n",
    "\n",
    "    N = y.shape[1]\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False)\n",
    "    x_coords, y_coords = [], []\n",
    "    for yi in y:\n",
    "        weights = yi / yi.sum() if yi.sum() > 0 else np.zeros_like(yi)\n",
    "        x_coords.append(np.sum(weights * np.cos(angles)))\n",
    "        y_coords.append(np.sum(weights * np.sin(angles)))\n",
    "    x_coords, y_coords = np.array(x_coords), np.array(y_coords)\n",
    "\n",
    "\n",
    "    hist, xedges, yedges = np.histogram2d(x_coords, y_coords, bins=bins)\n",
    "    xcenters = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    ycenters = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "    X, Y = np.meshgrid(xcenters, ycenters)\n",
    "    Z = hist.T  \n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=\"YlGnBu\", edgecolor=\"none\", alpha=0.95)\n",
    "    fig.colorbar(surf, shrink=0.6, aspect=10, label=\"Molecule Frequency\")\n",
    "\n",
    "    boundary_x = np.cos(angles).tolist() + [np.cos(angles[0])]\n",
    "    boundary_y = np.sin(angles).tolist() + [np.sin(angles[0])]\n",
    "    ax.plot(boundary_x, boundary_y, zs=0, color='gray', linestyle='--', linewidth=1)\n",
    "    for i, (bx, by) in enumerate(zip(boundary_x[:-1], boundary_y[:-1])):\n",
    "        ax.text(1.2*bx, 1.2*by, 0, task_names[i], fontsize=9, ha='center', va='center')\n",
    "\n",
    "    ax.set_zlabel(\"Frequency\")\n",
    "    ax.set_title(\"Tox21 12-Label Dodecagon 3D Frequency Plot\", fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_df = train_dataset.to_dataframe()\n",
    "plot_12xagon_3d_frequency(train_df, exclude_no_finding=True, bins=50)\n",
    "plot_12xagon_3d_frequency(valid_df, exclude_no_finding=True, bins=50)\n",
    "plot_12xagon_3d_frequency(test_df, exclude_no_finding=True, bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d291832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
