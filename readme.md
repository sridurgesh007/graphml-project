# CS5284 Project
## Molecular Toxicity Prediction with Graph Neural Networks

To recreate the environment run in the PowerShell:
`conda env create -f tox21_gnn_env.yaml
conda activate tox21_gnn`

Dataset can be extracted by unzipping the 'tox21_preprocessed.zip' file.

The molecular features are standerdized with StandarScaler. No scaling is yet done on the node features of the graph data.

ğŸ“‚ Data Access & Preparation
Due to GitHub file size limits, the preprocessed datasets, graph objects, and model checkpoints are hosted externally.

Step 1: Download Data
Please download the required files from the following Google Drive link:

ğŸ‘‰ [https://drive.google.com/drive/folders/1VFI8eS-SUUkvcUi4scdOVY5Ijq5J8boB?usp=sharing]

File structre to run below mentioned cells:
1. GINE Assay Multi-Head Cross Attention
2. PNA Cross Attention
3. Text Enhanced Weighted Assay GINE (MLP Projection)
4. Graph Transformer with Positional Encoding (Text+Graph)
```text
GNN-TEXT/
â”‚
â”œâ”€â”€ ğŸ“ graphs/                  # PyTorch Geometric Graph Objects (.pt)
â”‚   â”œâ”€â”€ train_2d.pt             # Serialized graph list for training set
â”‚   â”œâ”€â”€ val_2d.pt               # Serialized graph list for validation set
â”‚   â””â”€â”€ test_2d.pt              # Serialized graph list for test set
â”‚
â”œâ”€â”€ ğŸ“ processed/               # Tabular Data & Feature Vectors
    â”œâ”€â”€ train_clean.csv         # Cleaned SMILES, Labels (12 tasks), and Weights
    â”œâ”€â”€ val_clean.csv
    â”œâ”€â”€ test_clean.csv
    â”‚
    â”œâ”€â”€ train_ecfp4.npz         # Compressed NumPy archive: ECFP4 Fingerprints (2048-bit)
    â”œâ”€â”€ val_ecfp4.npz
    â”œâ”€â”€ test_ecfp4.npz
    â”‚
    â”œâ”€â”€ train_rdkit_desc.npz    # Compressed NumPy archive: Standardized RDKit Descriptors
    â”œâ”€â”€ val_rdkit_desc.npz
    â””â”€â”€ test_rdkit_desc.npz
```
This structure reflects the contents of your graphml_llm folder, including the inference scripts, training logs, and the critical checkpoint files required to run the Glass-Box model.

ğŸ“‚ GNN-LLM Directory Structure
To run the Glass-Box Multimodal LLM, ensure your graphml_llm directory matches the structure below. This module contains the Python scripts for training/inference and the LoRA checkpoints for the DeepSeek-R1 backbone.

```text
graphml_llm/
â”‚
â”œâ”€â”€ ğŸ“ python_files/            # Core Scripts
â”‚   â”œâ”€â”€ llm_train.py            # Main training loop (LoRA + Multi-Head Loss)
â”‚   â””â”€â”€ inference.py            # Inference script for generating explanations
â”‚
â”œâ”€â”€ ğŸ“ sample/                  # Sample Outputs
â”‚   â””â”€â”€ glassbox_final_val_results_graphhead.json  # Validation results from Graph Head
â”‚
â”œâ”€â”€ ğŸ“ log files/               # Training Logs
â”‚   â”œâ”€â”€ fusion_train_289517.log
â”‚   â”œâ”€â”€ fusion_train_289774.log
â”‚   â””â”€â”€ fusion_train_289876.log
â”‚
â”œâ”€â”€ ğŸ“ checkpoints_labelaux_fixed/
  â””â”€â”€ ğŸ“ checkpoint_best/     #  Best Model Artifacts (Required for Inference)
       â”œâ”€â”€ adapter_config.json # LoRA configuration
       â”œâ”€â”€ graph_head.pt       # Saved weights for the Graph Prediction Head
       â”œâ”€â”€ llm_head.pt         # Saved weights for the LLM Prediction Head
       â”œâ”€â”€ special_tokens_map.json
       â”œâ”€â”€ tokenizer.json      # Custom tokenizer with <GRAPH> tokens
       â”œâ”€â”€ tokenizer_config.json
       â””â”€â”€ README.md           # Model specific documentation
For checkpoint safe tensor file and projector.pt please check google drive link
Google Drive/
â”‚
â”œâ”€â”€ ğŸ“ graph_ml/
   â”‚
   â””â”€â”€ ğŸ“ Safe tensor file/        # Critical LLM Checkpoints
       â”œâ”€â”€ adapter_model.safetensors  # LoRA Adapter weights for DeepSeek-R1
       â””â”€â”€ projector.pt               # Trained Graph-to-LLM Projector weights
```


