{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2f310b",
   "metadata": {},
   "source": [
    "***approach 1 2d graph , descriptors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e6d1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_max_pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19ff8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data WITHOUT ECFP...\n",
      "Initializing Text-Enhanced GNN WITHOUT ECFP...\n",
      "Node features: 5\n",
      "Edge features: 6\n",
      "Descriptor features: 10\n",
      "Number of tasks: 12\n",
      "\n",
      "Using Assay Prompts:\n",
      "  NR-AR: androgen receptor binding and endocrine disruption potential\n",
      "  NR-AR-LBD: androgen receptor ligand binding domain interaction\n",
      "  NR-AhR: aryl hydrocarbon receptor activation and xenobiotic metabolism\n",
      "  NR-Aromatase: aromatase enzyme inhibition and steroid metabolism\n",
      "  NR-ER: estrogen receptor binding and hormonal activity\n",
      "  NR-ER-LBD: estrogen receptor ligand binding domain interaction\n",
      "  NR-PPAR-gamma: peroxisome proliferator-activated receptor gamma activation\n",
      "  SR-ARE: antioxidant response element activation and oxidative stress\n",
      "  SR-ATAD5: ATAD5 biomarker response and genotoxicity\n",
      "  SR-HSE: heat shock response element activation and protein stress\n",
      "  SR-MMP: mitochondrial membrane potential disruption\n",
      "  SR-p53: p53 tumor suppressor pathway activation and DNA damage\n",
      "\n",
      "Model parameters: 408,007\n",
      "\n",
      "Starting Training...\n",
      "Epoch | Train Loss | Val ROC-AUC | Val PR-AUC | LR\n",
      "-------------------------------------------------------\n",
      "    1 | 0.4317      | 0.5860      | 0.1102    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.5860)\n",
      "    2 | 0.2430      | 0.6409      | 0.1633    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.6409)\n",
      "    3 | 0.2068      | 0.6785      | 0.2053    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.6785)\n",
      "    4 | 0.1957      | 0.6726      | 0.2023    | 2.00e-04\n",
      "    5 | 0.1902      | 0.6831      | 0.1999    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.6831)\n",
      "    6 | 0.1865      | 0.6867      | 0.2003    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.6867)\n",
      "    7 | 0.1832      | 0.7138      | 0.2211    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7138)\n",
      "    8 | 0.1803      | 0.7241      | 0.2390    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7241)\n",
      "    9 | 0.1788      | 0.7148      | 0.2318    | 2.00e-04\n",
      "   10 | 0.1775      | 0.7292      | 0.2476    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7292)\n",
      "   11 | 0.1749      | 0.7338      | 0.2508    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7338)\n",
      "   12 | 0.1727      | 0.7158      | 0.2360    | 2.00e-04\n",
      "   13 | 0.1734      | 0.7352      | 0.2506    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7352)\n",
      "   14 | 0.1711      | 0.7334      | 0.2442    | 2.00e-04\n",
      "   15 | 0.1699      | 0.7326      | 0.2482    | 2.00e-04\n",
      "   16 | 0.1691      | 0.7283      | 0.2536    | 2.00e-04\n",
      "   17 | 0.1675      | 0.7238      | 0.2393    | 2.00e-04\n",
      "   18 | 0.1674      | 0.7299      | 0.2508    | 2.00e-04\n",
      "   19 | 0.1658      | 0.7336      | 0.2605    | 2.00e-04\n",
      "   20 | 0.1651      | 0.7323      | 0.2654    | 2.00e-04\n",
      "   21 | 0.1631      | 0.7377      | 0.2622    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7377)\n",
      "   22 | 0.1620      | 0.7437      | 0.2713    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7437)\n",
      "   23 | 0.1629      | 0.7364      | 0.2619    | 2.00e-04\n",
      "   24 | 0.1599      | 0.7402      | 0.2657    | 2.00e-04\n",
      "   25 | 0.1605      | 0.7453      | 0.2725    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7453)\n",
      "   26 | 0.1594      | 0.7419      | 0.2674    | 2.00e-04\n",
      "   27 | 0.1591      | 0.7366      | 0.2681    | 2.00e-04\n",
      "   28 | 0.1580      | 0.7400      | 0.2704    | 2.00e-04\n",
      "   29 | 0.1567      | 0.7464      | 0.2751    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7464)\n",
      "   30 | 0.1555      | 0.7389      | 0.2724    | 2.00e-04\n",
      "   31 | 0.1554      | 0.7438      | 0.2716    | 2.00e-04\n",
      "   32 | 0.1557      | 0.7380      | 0.2635    | 2.00e-04\n",
      "   33 | 0.1530      | 0.7358      | 0.2664    | 2.00e-04\n",
      "   34 | 0.1537      | 0.7482      | 0.2782    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7482)\n",
      "   35 | 0.1515      | 0.7481      | 0.2722    | 2.00e-04\n",
      "   36 | 0.1529      | 0.7554      | 0.2864    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7554)\n",
      "   37 | 0.1517      | 0.7363      | 0.2663    | 2.00e-04\n",
      "   38 | 0.1500      | 0.7470      | 0.2790    | 2.00e-04\n",
      "   39 | 0.1502      | 0.7391      | 0.2728    | 2.00e-04\n",
      "   40 | 0.1498      | 0.7445      | 0.2721    | 2.00e-04\n",
      "   41 | 0.1488      | 0.7401      | 0.2762    | 2.00e-04\n",
      "   42 | 0.1489      | 0.7367      | 0.2745    | 2.00e-04\n",
      "   43 | 0.1480      | 0.7324      | 0.2612    | 2.00e-04\n",
      "   44 | 0.1472      | 0.7561      | 0.2889    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7561)\n",
      "   45 | 0.1460      | 0.7530      | 0.2898    | 2.00e-04\n",
      "   46 | 0.1460      | 0.7543      | 0.2954    | 2.00e-04\n",
      "   47 | 0.1445      | 0.7552      | 0.2841    | 2.00e-04\n",
      "   48 | 0.1450      | 0.7584      | 0.2888    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7584)\n",
      "   49 | 0.1447      | 0.7517      | 0.2838    | 2.00e-04\n",
      "   50 | 0.1433      | 0.7454      | 0.2747    | 2.00e-04\n",
      "   51 | 0.1429      | 0.7591      | 0.2908    | 2.00e-04\n",
      "  → New best! (ROC-AUC: 0.7591)\n",
      "   52 | 0.1415      | 0.7496      | 0.2795    | 2.00e-04\n",
      "   53 | 0.1406      | 0.7498      | 0.2726    | 2.00e-04\n",
      "   54 | 0.1423      | 0.7443      | 0.2850    | 2.00e-04\n",
      "   55 | 0.1395      | 0.7534      | 0.2828    | 2.00e-04\n",
      "   56 | 0.1395      | 0.7464      | 0.2791    | 2.00e-04\n",
      "   57 | 0.1404      | 0.7448      | 0.2766    | 2.00e-04\n",
      "   58 | 0.1391      | 0.7491      | 0.2707    | 2.00e-04\n",
      "   59 | 0.1391      | 0.7531      | 0.2833    | 2.00e-04\n",
      "   60 | 0.1378      | 0.7503      | 0.2843    | 2.00e-04\n",
      "   61 | 0.1374      | 0.7429      | 0.2842    | 2.00e-04\n",
      "   62 | 0.1377      | 0.7518      | 0.2883    | 1.00e-04\n",
      "   63 | 0.1335      | 0.7552      | 0.2906    | 1.00e-04\n",
      "   64 | 0.1347      | 0.7532      | 0.2818    | 1.00e-04\n",
      "   65 | 0.1331      | 0.7597      | 0.2894    | 1.00e-04\n",
      "  → New best! (ROC-AUC: 0.7597)\n",
      "   66 | 0.1318      | 0.7516      | 0.2891    | 1.00e-04\n",
      "   67 | 0.1325      | 0.7529      | 0.2853    | 1.00e-04\n",
      "   68 | 0.1315      | 0.7593      | 0.2931    | 1.00e-04\n",
      "   69 | 0.1307      | 0.7575      | 0.2843    | 1.00e-04\n",
      "   70 | 0.1313      | 0.7551      | 0.2891    | 1.00e-04\n",
      "   71 | 0.1308      | 0.7540      | 0.2814    | 1.00e-04\n",
      "   72 | 0.1299      | 0.7521      | 0.2854    | 1.00e-04\n",
      "   73 | 0.1295      | 0.7550      | 0.2921    | 1.00e-04\n",
      "   74 | 0.1302      | 0.7589      | 0.2959    | 1.00e-04\n",
      "   75 | 0.1288      | 0.7527      | 0.2860    | 1.00e-04\n",
      "   76 | 0.1283      | 0.7581      | 0.2975    | 5.00e-05\n",
      "   77 | 0.1281      | 0.7602      | 0.2903    | 5.00e-05\n",
      "  → New best! (ROC-AUC: 0.7602)\n",
      "   78 | 0.1264      | 0.7575      | 0.2883    | 5.00e-05\n",
      "   79 | 0.1253      | 0.7613      | 0.2923    | 5.00e-05\n",
      "  → New best! (ROC-AUC: 0.7613)\n",
      "   80 | 0.1274      | 0.7603      | 0.2889    | 5.00e-05\n",
      "   81 | 0.1265      | 0.7611      | 0.2929    | 5.00e-05\n",
      "   82 | 0.1260      | 0.7569      | 0.2883    | 5.00e-05\n",
      "   83 | 0.1262      | 0.7585      | 0.2881    | 5.00e-05\n",
      "   84 | 0.1258      | 0.7608      | 0.2932    | 5.00e-05\n",
      "   85 | 0.1256      | 0.7597      | 0.2911    | 5.00e-05\n",
      "   86 | 0.1247      | 0.7594      | 0.2904    | 5.00e-05\n",
      "   87 | 0.1251      | 0.7614      | 0.2884    | 5.00e-05\n",
      "  → New best! (ROC-AUC: 0.7614)\n",
      "   88 | 0.1228      | 0.7602      | 0.2881    | 5.00e-05\n",
      "   89 | 0.1245      | 0.7607      | 0.2869    | 5.00e-05\n",
      "   90 | 0.1241      | 0.7590      | 0.2856    | 2.50e-05\n",
      "   91 | 0.1243      | 0.7577      | 0.2875    | 2.50e-05\n",
      "   92 | 0.1236      | 0.7593      | 0.2884    | 2.50e-05\n",
      "   93 | 0.1223      | 0.7580      | 0.2858    | 2.50e-05\n",
      "   94 | 0.1225      | 0.7588      | 0.2870    | 2.50e-05\n",
      "   95 | 0.1223      | 0.7584      | 0.2874    | 2.50e-05\n",
      "   96 | 0.1222      | 0.7577      | 0.2875    | 2.50e-05\n",
      "   97 | 0.1233      | 0.7587      | 0.2920    | 2.50e-05\n",
      "   98 | 0.1225      | 0.7587      | 0.2908    | 2.50e-05\n",
      "   99 | 0.1218      | 0.7564      | 0.2866    | 2.50e-05\n",
      "  100 | 0.1220      | 0.7567      | 0.2888    | 2.50e-05\n",
      "\n",
      "Training completed. Best validation ROC-AUC: 0.7614\n",
      "Loaded best model for testing\n",
      "\n",
      "=================================================================\n",
      "FINAL TEST METRICS (Text-Enhanced GNN WITHOUT ECFP)\n",
      "=================================================================\n",
      "NR-AR           | ROC-AUC: 0.7235 | PR-AUC: 0.3096\n",
      "NR-AR-LBD       | ROC-AUC: 0.7627 | PR-AUC: 0.2159\n",
      "NR-AhR          | ROC-AUC: 0.7750 | PR-AUC: 0.3579\n",
      "NR-Aromatase    | ROC-AUC: 0.7279 | PR-AUC: 0.1875\n",
      "NR-ER           | ROC-AUC: 0.6972 | PR-AUC: 0.2369\n",
      "NR-ER-LBD       | ROC-AUC: 0.7084 | PR-AUC: 0.1268\n",
      "NR-PPAR-gamma   | ROC-AUC: 0.7003 | PR-AUC: 0.0819\n",
      "SR-ARE          | ROC-AUC: 0.6730 | PR-AUC: 0.2605\n",
      "SR-ATAD5        | ROC-AUC: 0.7274 | PR-AUC: 0.1391\n",
      "SR-HSE          | ROC-AUC: 0.7240 | PR-AUC: 0.1630\n",
      "SR-MMP          | ROC-AUC: 0.8098 | PR-AUC: 0.3654\n",
      "SR-p53          | ROC-AUC: 0.7263 | PR-AUC: 0.2531\n",
      "-----------------------------------------------------------------\n",
      "Mean            | ROC-AUC: 0.7296 | PR-AUC: 0.2248\n",
      "\n",
      "Model saved as 'text_enhanced_no_ecfp_final.pt'\n",
      "\n",
      "Learned assay prompt similarities:\n",
      "  NR-AhR          ↔ SR-HSE         : 0.175\n",
      "  NR-ER           ↔ NR-ER-LBD      : 0.149\n",
      "  NR-PPAR-gamma   ↔ SR-MMP         : 0.146\n",
      "  NR-AR           ↔ NR-ER-LBD      : 0.141\n",
      "  NR-AhR          ↔ NR-PPAR-gamma  : 0.133\n"
     ]
    }
   ],
   "source": [
    "# ---- Load graphs ----\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# ============================\n",
    "# Text-Enhanced Model WITHOUT ECFP\n",
    "# ============================\n",
    "\n",
    "class TextEnhancedNoECFP(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_tasks = n_tasks\n",
    "        self.desc_feature_dim = desc_feature_dim\n",
    "\n",
    "        # --- GNN Backbone ---\n",
    "        nn1 = nn.Sequential(\n",
    "            nn.Linear(node_feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "        self.gnn_conv1 = GINEConv(nn1, edge_dim=edge_feature_dim)\n",
    "\n",
    "        nn2 = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "        self.gnn_conv2 = GINEConv(nn2, edge_dim=edge_feature_dim)\n",
    "\n",
    "        self.gnn_batch_norm1 = nn.BatchNorm1d(128)\n",
    "        self.gnn_batch_norm2 = nn.BatchNorm1d(128)\n",
    "\n",
    "        # Graph output dimension\n",
    "        gnn_out_dim = 256  # mean + max pool\n",
    "\n",
    "        # --- Learnable Text Prompts for Each Assay ---\n",
    "        self.assay_prompts = nn.Parameter(torch.randn(n_tasks, 128))\n",
    "        \n",
    "        # Text projection\n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # --- Assay-Conditioned Fusion ---\n",
    "        self.assay_weights = nn.Parameter(torch.ones(n_tasks, 2))  # [12, 2] for gnn, desc\n",
    "        \n",
    "        # Final classifier (NO ECFP dimension)\n",
    "        classifier_input_dim = 256 + desc_feature_dim + 128  # gnn + desc + text ONLY\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_tasks)\n",
    "        )\n",
    "\n",
    "    def forward_gnn(self, x, edge_index, edge_attr, batch):\n",
    "        # GNN processing\n",
    "        x = self.gnn_conv1(x, edge_index, edge_attr)\n",
    "        x = self.gnn_batch_norm1(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        x = self.gnn_conv2(x, edge_index, edge_attr)\n",
    "        x = self.gnn_batch_norm2(x)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        # Readout\n",
    "        mean_pool = global_mean_pool(x, batch)\n",
    "        max_pool = global_max_pool(x, batch)\n",
    "        return torch.cat([mean_pool, max_pool], dim=1)\n",
    "\n",
    "    def forward(self, data, assay_attention=None):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        B = data.num_graphs\n",
    "\n",
    "        # 1. Process GNN features\n",
    "        graph_out = self.forward_gnn(x, edge_index, edge_attr, batch)  # [B, 256]\n",
    "        desc_out = data.desc_features.view(B, self.desc_feature_dim)   # [B, desc_dim]\n",
    "\n",
    "        # 2. Text prompts for assay conditioning\n",
    "        if assay_attention is None:\n",
    "            # Default: equal attention to all assays\n",
    "            text_weights = torch.ones(B, self.n_tasks, device=graph_out.device) / self.n_tasks\n",
    "        else:\n",
    "            text_weights = assay_attention\n",
    "        \n",
    "        # Weighted average of text prompts\n",
    "        text_feat = torch.einsum('bi,ij->bj', text_weights, self.assay_prompts)  # [B, 128]\n",
    "        text_feat = self.text_proj(text_feat)  # [B, 128]\n",
    "\n",
    "        # 3. Assay-weighted fusion of modalities\n",
    "        modality_weights = F.softmax(self.assay_weights, dim=1)  # [12, 2]\n",
    "        \n",
    "        # Use average weights across assays\n",
    "        avg_weights = modality_weights.mean(dim=0)  # [2]\n",
    "        \n",
    "        # Apply weights to modalities (NO ECFP)\n",
    "        weighted_graph = graph_out * avg_weights[0]\n",
    "        weighted_desc = desc_out * avg_weights[1]\n",
    "\n",
    "        # 4. Concatenate all features (NO ECFP)\n",
    "        combined = torch.cat([weighted_graph, weighted_desc, text_feat], dim=1)\n",
    "        \n",
    "        # 5. Final prediction\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# ============================\n",
    "# Text Prompts Definition\n",
    "# ============================\n",
    "\n",
    "# Define meaningful text prompts for each assay\n",
    "ASSAY_DESCRIPTIONS = {\n",
    "    \"NR-AR\": \"androgen receptor binding and endocrine disruption potential\",\n",
    "    \"NR-AR-LBD\": \"androgen receptor ligand binding domain interaction\", \n",
    "    \"NR-AhR\": \"aryl hydrocarbon receptor activation and xenobiotic metabolism\",\n",
    "    \"NR-Aromatase\": \"aromatase enzyme inhibition and steroid metabolism\",\n",
    "    \"NR-ER\": \"estrogen receptor binding and hormonal activity\",\n",
    "    \"NR-ER-LBD\": \"estrogen receptor ligand binding domain interaction\",\n",
    "    \"NR-PPAR-gamma\": \"peroxisome proliferator-activated receptor gamma activation\",\n",
    "    \"SR-ARE\": \"antioxidant response element activation and oxidative stress\",\n",
    "    \"SR-ATAD5\": \"ATAD5 biomarker response and genotoxicity\",\n",
    "    \"SR-HSE\": \"heat shock response element activation and protein stress\",\n",
    "    \"SR-MMP\": \"mitochondrial membrane potential disruption\",\n",
    "    \"SR-p53\": \"p53 tumor suppressor pathway activation and DNA damage\"\n",
    "}\n",
    "\n",
    "# Convert to list in correct order\n",
    "ASSAY_TEXTS = [ASSAY_DESCRIPTIONS[assay] for assay in ASSAYS]\n",
    "\n",
    "# ============================\n",
    "# Training Components\n",
    "# ============================\n",
    "\n",
    "def train_text_enhanced_epoch(loader, model, optimizer, criterion, device, n_tasks):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_graphs = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        B = batch.num_graphs\n",
    "        \n",
    "        # Strategy 1: Equal attention to all assays\n",
    "        assay_attention = torch.ones(B, n_tasks, device=device) / n_tasks\n",
    "        \n",
    "        # Strategy 2: Focus on assays with positive labels in this batch\n",
    "        y_batch = batch.y.float().view(B, n_tasks)\n",
    "        w_batch = batch.weight.float().view(B, n_tasks)\n",
    "        labeled_mask = (w_batch > 0).float()\n",
    "        \n",
    "        # If sample has specific assay labels, focus on those\n",
    "        if labeled_mask.sum() > 0:\n",
    "            assay_attention = labeled_mask / labeled_mask.sum(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "        \n",
    "        logits = model(batch, assay_attention)\n",
    "\n",
    "        # Targets and weights\n",
    "        y = batch.y.float().view(-1, n_tasks)\n",
    "        w = batch.weight.float().view(-1, n_tasks)\n",
    "\n",
    "        # Compute loss (only on labeled positions)\n",
    "        loss_unreduced = criterion(logits, y)\n",
    "        mask = (w > 0).float()\n",
    "        loss = (loss_unreduced * mask).sum() / mask.sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        total_graphs += B\n",
    "\n",
    "    return total_loss / total_graphs\n",
    "\n",
    "def evaluate(loader, model, device, assays):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    all_weights = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            B = batch.num_graphs\n",
    "            \n",
    "            # For evaluation, use equal attention to all assays\n",
    "            assay_attention = torch.ones(B, len(assays), device=device) / len(assays)\n",
    "            \n",
    "            logits = model(batch, assay_attention)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            y = batch.y.float().view(-1, len(assays))\n",
    "            w = batch.weight.float().view(-1, len(assays))\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "            all_weights.append(w.cpu())\n",
    "\n",
    "    probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    labels = torch.cat(all_labels, dim=0).numpy()\n",
    "    weights = torch.cat(all_weights, dim=0).numpy()\n",
    "\n",
    "    roc_scores = {}\n",
    "    pr_scores = {}\n",
    "\n",
    "    for j, assay in enumerate(assays):\n",
    "        mask = weights[:, j] > 0\n",
    "        if mask.sum() < 5:\n",
    "            roc_scores[assay] = np.nan\n",
    "            pr_scores[assay] = np.nan\n",
    "            continue\n",
    "\n",
    "        y_true = labels[mask, j]\n",
    "        y_pred = probs[mask, j]\n",
    "\n",
    "        try:\n",
    "            roc_scores[assay] = roc_auc_score(y_true, y_pred)\n",
    "            pr_scores[assay] = average_precision_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            roc_scores[assay] = np.nan\n",
    "            pr_scores[assay] = np.nan\n",
    "\n",
    "    mean_roc = np.nanmean(list(roc_scores.values()))\n",
    "    mean_pr = np.nanmean(list(pr_scores.values()))\n",
    "    return roc_scores, pr_scores, mean_roc, mean_pr\n",
    "\n",
    "# ============================\n",
    "# Data Preparation (NO ECFP)\n",
    "# ============================\n",
    "\n",
    "# Remove ECFP from your data loading\n",
    "print(\"Preparing data WITHOUT ECFP...\")\n",
    "train_graphs = torch.load(\"graphs/train_2d.pt\")\n",
    "val_graphs   = torch.load(\"graphs/val_2d.pt\")\n",
    "test_graphs  = torch.load(\"graphs/test_2d.pt\")\n",
    "# Create zero ECFP features (minimal dimension to avoid errors)\n",
    "train_fp = np.zeros((len(train_graphs), 1), dtype=np.float32)\n",
    "val_fp = np.zeros((len(val_graphs), 1), dtype=np.float32)  \n",
    "test_fp = np.zeros((len(test_graphs), 1), dtype=np.float32)\n",
    "fp_dim = 1\n",
    "\n",
    "# Keep descriptors\n",
    "if use_desc:\n",
    "    train_desc = np.load(r\"E:\\graphml project\\novel\\processed\\train_rdkit_desc.npz\")[\"X\"]\n",
    "    val_desc = np.load(r\"E:\\graphml project\\novel\\processed\\val_rdkit_desc.npz\")[\"X\"]\n",
    "    test_desc = np.load(r\"E:\\graphml project\\novel\\processed\\test_rdkit_desc.npz\")[\"X\"]\n",
    "    desc_dim = train_desc.shape[1]\n",
    "else:\n",
    "    desc_dim = 32\n",
    "    train_desc = np.zeros((len(train_graphs), desc_dim), dtype=np.float32)\n",
    "    val_desc = np.zeros((len(val_graphs), desc_dim), dtype=np.float32)\n",
    "    test_desc = np.zeros((len(test_graphs), desc_dim), dtype=np.float32)\n",
    "\n",
    "# Attach features (ECFP will be zeros)\n",
    "def attach_features_no_ecfp(graph_list, desc_array):\n",
    "    for i, g in enumerate(graph_list):\n",
    "        g.fp_features = torch.zeros(1).float()  # Minimal ECFP\n",
    "        g.desc_features = torch.from_numpy(desc_array[i]).float()\n",
    "    return graph_list\n",
    "\n",
    "train_graphs = attach_features_no_ecfp(train_graphs, train_desc)\n",
    "val_graphs = attach_features_no_ecfp(val_graphs, val_desc)\n",
    "test_graphs = attach_features_no_ecfp(test_graphs, test_desc)\n",
    "\n",
    "# DataLoaders (same as before)\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_graphs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ============================\n",
    "# Main Training Pipeline\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    EPOCHS = 100\n",
    "    LR = 2e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "\n",
    "    print(\"Initializing Text-Enhanced GNN WITHOUT ECFP...\")\n",
    "    \n",
    "    # Get dimensions\n",
    "    sample = train_graphs[0]\n",
    "    node_dim = sample.x.size(1)\n",
    "    edge_dim = sample.edge_attr.size(1)\n",
    "    \n",
    "    print(f\"Node features: {node_dim}\")\n",
    "    print(f\"Edge features: {edge_dim}\")\n",
    "    print(f\"Descriptor features: {desc_dim}\")\n",
    "    print(f\"Number of tasks: {len(ASSAYS)}\")\n",
    "    print(\"\\nUsing Assay Prompts:\")\n",
    "    for assay, desc in ASSAY_DESCRIPTIONS.items():\n",
    "        print(f\"  {assay}: {desc}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TextEnhancedNoECFP(\n",
    "        node_feature_dim=node_dim,\n",
    "        edge_feature_dim=edge_dim,\n",
    "        desc_feature_dim=desc_dim,\n",
    "        n_tasks=len(ASSAYS)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=LR, \n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=10, verbose=True\n",
    "    )\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_roc = -1.0\n",
    "    best_state = None\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"\\nStarting Training...\")\n",
    "    print(\"Epoch | Train Loss | Val ROC-AUC | Val PR-AUC | LR\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # Training\n",
    "        train_loss = train_text_enhanced_epoch(\n",
    "            train_loader, model, optimizer, criterion, device, len(ASSAYS)\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        roc_val, pr_val, mean_roc_val, mean_pr_val = evaluate(val_loader, model, device, ASSAYS)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(mean_roc_val)\n",
    "        \n",
    "        print(f\"{epoch:5d} | {train_loss:.4f}      | {mean_roc_val:.4f}      | {mean_pr_val:.4f}    | {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if mean_roc_val > best_val_roc:\n",
    "            best_val_roc = mean_roc_val\n",
    "            best_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"text_enhanced_no_ecfp_best.pt\")\n",
    "            print(f\"  → New best! (ROC-AUC: {best_val_roc:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nTraining completed. Best validation ROC-AUC: {best_val_roc:.4f}\")\n",
    "    \n",
    "    # Load best model for testing\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(\"Loaded best model for testing\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    roc_test, pr_test, mean_roc_test, mean_pr_test = evaluate(test_loader, model, device, ASSAYS)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 65)\n",
    "    print(\"FINAL TEST METRICS (Text-Enhanced GNN WITHOUT ECFP)\")\n",
    "    print(\"=\" * 65)\n",
    "    for assay in ASSAYS:\n",
    "        print(f\"{assay:15s} | ROC-AUC: {roc_test[assay]:.4f} | PR-AUC: {pr_test[assay]:.4f}\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Mean':15s} | ROC-AUC: {mean_roc_test:.4f} | PR-AUC: {mean_pr_test:.4f}\")\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'assay_prompts': model.assay_prompts.detach().cpu(),\n",
    "        'assay_descriptions': ASSAY_DESCRIPTIONS,\n",
    "        'test_metrics': {\n",
    "            'roc_auc': roc_test,\n",
    "            'pr_auc': pr_test,\n",
    "            'mean_roc': mean_roc_test,\n",
    "            'mean_pr': mean_pr_test\n",
    "        },\n",
    "        'config': {\n",
    "            'use_ecfp': False,\n",
    "            'use_text_prompts': True,\n",
    "            'use_descriptors': True\n",
    "        }\n",
    "    }, \"text_enhanced_no_ecfp_final.pt\")\n",
    "    \n",
    "    print(\"\\nModel saved as 'text_enhanced_no_ecfp_final.pt'\")\n",
    "    \n",
    "    # Show learned prompt similarities\n",
    "    print(\"\\nLearned assay prompt similarities:\")\n",
    "    prompts = model.assay_prompts.detach().cpu()\n",
    "    similarities = F.cosine_similarity(prompts.unsqueeze(1), prompts.unsqueeze(0), dim=2)\n",
    "    \n",
    "    # Show top similar assay pairs\n",
    "    similar_pairs = []\n",
    "    for i in range(len(ASSAYS)):\n",
    "        for j in range(i + 1, len(ASSAYS)):\n",
    "            similar_pairs.append((i, j, similarities[i, j].item()))\n",
    "    \n",
    "    similar_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    for i, j, sim in similar_pairs[:5]:  # Top 5 most similar\n",
    "        print(f\"  {ASSAYS[i]:15s} ↔ {ASSAYS[j]:15s}: {sim:.3f}\")\n",
    "\n",
    "# Run the training\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4848a",
   "metadata": {},
   "source": [
    "***PNA TEXT***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25eb355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridurgesh\\AppData\\Local\\Temp\\ipykernel_22636\\3890087251.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_graphs = torch.load(\"graphs/train_2d.pt\")\n",
      "C:\\Users\\sridurgesh\\AppData\\Local\\Temp\\ipykernel_22636\\3890087251.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_graphs   = torch.load(\"graphs/val_2d.pt\")\n",
      "C:\\Users\\sridurgesh\\AppData\\Local\\Temp\\ipykernel_22636\\3890087251.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_graphs  = torch.load(\"graphs/test_2d.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay Prompts:\n",
      "  NR-AR: androgen receptor binding and endocrine disruption potential\n",
      "  NR-AR-LBD: androgen receptor ligand binding domain interaction\n",
      "  NR-AhR: aryl hydrocarbon receptor activation and xenobiotic metabolism\n",
      "  NR-Aromatase: aromatase enzyme inhibition and steroid metabolism\n",
      "  NR-ER: estrogen receptor binding and hormonal activity\n",
      "  NR-ER-LBD: estrogen receptor ligand binding domain interaction\n",
      "  NR-PPAR-gamma: peroxisome proliferator-activated receptor gamma activation\n",
      "  SR-ARE: antioxidant response element activation and oxidative stress\n",
      "  SR-ATAD5: ATAD5 biomarker response and genotoxicity\n",
      "  SR-HSE: heat shock response element activation and protein stress\n",
      "  SR-MMP: mitochondrial membrane potential disruption and cytotoxicity\n",
      "  SR-p53: p53 tumor suppressor pathway activation and DNA damage response\n",
      "Using device: cuda\n",
      "Node features: 5\n",
      "Edge features: 6\n",
      "Descriptor features: 10\n",
      "Number of tasks: 12\n",
      "PNA Model parameters: 1,543,564\n",
      "\n",
      "Starting PNA Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.4582 | Val ROC: 0.5769 | LR: 2.00e-04\n",
      "  → New best! (ROC: 0.5769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Loss: 0.2485 | Val ROC: 0.6654 | LR: 2.00e-04\n",
      "  → New best! (ROC: 0.6654)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Loss: 0.2050 | Val ROC: 0.6935 | LR: 2.00e-04\n",
      "  → New best! (ROC: 0.6935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Loss: 0.1913 | Val ROC: 0.6914 | LR: 1.99e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Loss: 0.1860 | Val ROC: 0.7147 | LR: 1.99e-04\n",
      "  → New best! (ROC: 0.7147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Loss: 0.1829 | Val ROC: 0.7163 | LR: 1.98e-04\n",
      "  → New best! (ROC: 0.7163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Loss: 0.1791 | Val ROC: 0.7220 | LR: 1.98e-04\n",
      "  → New best! (ROC: 0.7220)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Loss: 0.1780 | Val ROC: 0.7306 | LR: 1.97e-04\n",
      "  → New best! (ROC: 0.7306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Loss: 0.1761 | Val ROC: 0.7320 | LR: 1.96e-04\n",
      "  → New best! (ROC: 0.7320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Loss: 0.1738 | Val ROC: 0.7372 | LR: 1.95e-04\n",
      "  → New best! (ROC: 0.7372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Loss: 0.1726 | Val ROC: 0.7397 | LR: 1.94e-04\n",
      "  → New best! (ROC: 0.7397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Loss: 0.1716 | Val ROC: 0.7419 | LR: 1.93e-04\n",
      "  → New best! (ROC: 0.7419)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Loss: 0.1689 | Val ROC: 0.7474 | LR: 1.92e-04\n",
      "  → New best! (ROC: 0.7474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Loss: 0.1682 | Val ROC: 0.7447 | LR: 1.90e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Loss: 0.1669 | Val ROC: 0.7503 | LR: 1.89e-04\n",
      "  → New best! (ROC: 0.7503)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Loss: 0.1656 | Val ROC: 0.7528 | LR: 1.88e-04\n",
      "  → New best! (ROC: 0.7528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Loss: 0.1642 | Val ROC: 0.7506 | LR: 1.86e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Loss: 0.1642 | Val ROC: 0.7539 | LR: 1.84e-04\n",
      "  → New best! (ROC: 0.7539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Loss: 0.1632 | Val ROC: 0.7416 | LR: 1.83e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Loss: 0.1630 | Val ROC: 0.7557 | LR: 1.81e-04\n",
      "  → New best! (ROC: 0.7557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Loss: 0.1615 | Val ROC: 0.7527 | LR: 1.79e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Loss: 0.1613 | Val ROC: 0.7514 | LR: 1.77e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Loss: 0.1600 | Val ROC: 0.7586 | LR: 1.75e-04\n",
      "  → New best! (ROC: 0.7586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Loss: 0.1596 | Val ROC: 0.7546 | LR: 1.73e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Loss: 0.1583 | Val ROC: 0.7574 | LR: 1.71e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Loss: 0.1582 | Val ROC: 0.7535 | LR: 1.68e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Loss: 0.1559 | Val ROC: 0.7562 | LR: 1.66e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Loss: 0.1565 | Val ROC: 0.7653 | LR: 1.64e-04\n",
      "  → New best! (ROC: 0.7653)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Loss: 0.1557 | Val ROC: 0.7541 | LR: 1.61e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Loss: 0.1548 | Val ROC: 0.7641 | LR: 1.59e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Loss: 0.1541 | Val ROC: 0.7603 | LR: 1.56e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Loss: 0.1538 | Val ROC: 0.7661 | LR: 1.54e-04\n",
      "  → New best! (ROC: 0.7661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Loss: 0.1523 | Val ROC: 0.7623 | LR: 1.51e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Loss: 0.1529 | Val ROC: 0.7608 | LR: 1.48e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Loss: 0.1511 | Val ROC: 0.7599 | LR: 1.45e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | Loss: 0.1511 | Val ROC: 0.7663 | LR: 1.43e-04\n",
      "  → New best! (ROC: 0.7663)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | Loss: 0.1488 | Val ROC: 0.7614 | LR: 1.40e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | Loss: 0.1498 | Val ROC: 0.7633 | LR: 1.37e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | Loss: 0.1487 | Val ROC: 0.7635 | LR: 1.34e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Loss: 0.1480 | Val ROC: 0.7657 | LR: 1.31e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | Loss: 0.1471 | Val ROC: 0.7637 | LR: 1.28e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | Loss: 0.1467 | Val ROC: 0.7681 | LR: 1.25e-04\n",
      "  → New best! (ROC: 0.7681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | Loss: 0.1474 | Val ROC: 0.7638 | LR: 1.22e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 | Loss: 0.1466 | Val ROC: 0.7634 | LR: 1.19e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Loss: 0.1452 | Val ROC: 0.7652 | LR: 1.16e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | Loss: 0.1453 | Val ROC: 0.7690 | LR: 1.13e-04\n",
      "  → New best! (ROC: 0.7690)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 047 | Loss: 0.1441 | Val ROC: 0.7631 | LR: 1.09e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 | Loss: 0.1439 | Val ROC: 0.7661 | LR: 1.06e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 | Loss: 0.1430 | Val ROC: 0.7635 | LR: 1.03e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Loss: 0.1432 | Val ROC: 0.7678 | LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 051 | Loss: 0.1435 | Val ROC: 0.7632 | LR: 9.69e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 052 | Loss: 0.1413 | Val ROC: 0.7678 | LR: 9.37e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 053 | Loss: 0.1416 | Val ROC: 0.7658 | LR: 9.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 054 | Loss: 0.1397 | Val ROC: 0.7660 | LR: 8.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Loss: 0.1405 | Val ROC: 0.7667 | LR: 8.44e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 056 | Loss: 0.1404 | Val ROC: 0.7673 | LR: 8.13e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 057 | Loss: 0.1394 | Val ROC: 0.7676 | LR: 7.82e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 058 | Loss: 0.1388 | Val ROC: 0.7666 | LR: 7.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 059 | Loss: 0.1388 | Val ROC: 0.7677 | LR: 7.21e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 060 | Loss: 0.1375 | Val ROC: 0.7691 | LR: 6.91e-05\n",
      "  → New best! (ROC: 0.7691)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 061 | Loss: 0.1377 | Val ROC: 0.7645 | LR: 6.61e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 062 | Loss: 0.1370 | Val ROC: 0.7677 | LR: 6.32e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 063 | Loss: 0.1369 | Val ROC: 0.7639 | LR: 6.03e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 064 | Loss: 0.1354 | Val ROC: 0.7640 | LR: 5.74e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 065 | Loss: 0.1358 | Val ROC: 0.7669 | LR: 5.46e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 066 | Loss: 0.1351 | Val ROC: 0.7654 | LR: 5.18e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 067 | Loss: 0.1349 | Val ROC: 0.7689 | LR: 4.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 068 | Loss: 0.1342 | Val ROC: 0.7675 | LR: 4.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 069 | Loss: 0.1339 | Val ROC: 0.7674 | LR: 4.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 070 | Loss: 0.1332 | Val ROC: 0.7645 | LR: 4.12e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 071 | Loss: 0.1341 | Val ROC: 0.7670 | LR: 3.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 072 | Loss: 0.1333 | Val ROC: 0.7673 | LR: 3.63e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 073 | Loss: 0.1322 | Val ROC: 0.7658 | LR: 3.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 074 | Loss: 0.1318 | Val ROC: 0.7675 | LR: 3.15e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 075 | Loss: 0.1331 | Val ROC: 0.7690 | LR: 2.93e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 076 | Loss: 0.1331 | Val ROC: 0.7691 | LR: 2.71e-05\n",
      "  → New best! (ROC: 0.7691)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 077 | Loss: 0.1322 | Val ROC: 0.7709 | LR: 2.50e-05\n",
      "  → New best! (ROC: 0.7709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 078 | Loss: 0.1314 | Val ROC: 0.7693 | LR: 2.29e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 079 | Loss: 0.1320 | Val ROC: 0.7679 | LR: 2.10e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 080 | Loss: 0.1320 | Val ROC: 0.7690 | LR: 1.91e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 081 | Loss: 0.1311 | Val ROC: 0.7674 | LR: 1.73e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 082 | Loss: 0.1305 | Val ROC: 0.7678 | LR: 1.56e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 083 | Loss: 0.1318 | Val ROC: 0.7696 | LR: 1.39e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 084 | Loss: 0.1311 | Val ROC: 0.7698 | LR: 1.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 085 | Loss: 0.1297 | Val ROC: 0.7681 | LR: 1.09e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 086 | Loss: 0.1295 | Val ROC: 0.7678 | LR: 9.52e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 087 | Loss: 0.1307 | Val ROC: 0.7687 | LR: 8.22e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 088 | Loss: 0.1307 | Val ROC: 0.7693 | LR: 7.02e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 089 | Loss: 0.1306 | Val ROC: 0.7693 | LR: 5.91e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 090 | Loss: 0.1286 | Val ROC: 0.7699 | LR: 4.89e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 091 | Loss: 0.1298 | Val ROC: 0.7699 | LR: 3.97e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 092 | Loss: 0.1299 | Val ROC: 0.7690 | LR: 3.14e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 093 | Loss: 0.1298 | Val ROC: 0.7685 | LR: 2.41e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 094 | Loss: 0.1294 | Val ROC: 0.7709 | LR: 1.77e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 095 | Loss: 0.1298 | Val ROC: 0.7691 | LR: 1.23e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 096 | Loss: 0.1295 | Val ROC: 0.7686 | LR: 7.89e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 097 | Loss: 0.1279 | Val ROC: 0.7693 | LR: 4.44e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 098 | Loss: 0.1292 | Val ROC: 0.7682 | LR: 1.97e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 099 | Loss: 0.1290 | Val ROC: 0.7687 | LR: 4.93e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "e:\\anaconda\\envs\\tox21_gnn\\lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Loss: 0.1303 | Val ROC: 0.7707 | LR: 0.00e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridurgesh\\AppData\\Local\\Temp\\ipykernel_22636\\3890087251.py:360: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"pna_text_best.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 FINAL PNA TEST RESULTS:\n",
      "ROC-AUC: 0.7398\n",
      "PR-AUC: 0.2310\n",
      "\n",
      "Per-assay ROC-AUC:\n",
      "  NR-AR: 0.7649\n",
      "  NR-AR-LBD: 0.7996\n",
      "  NR-AhR: 0.8087\n",
      "  NR-Aromatase: 0.7024\n",
      "  NR-ER: 0.6388\n",
      "  NR-ER-LBD: 0.7250\n",
      "  NR-PPAR-gamma: 0.7562\n",
      "  SR-ARE: 0.6823\n",
      "  SR-ATAD5: 0.6953\n",
      "  SR-HSE: 0.7715\n",
      "  SR-MMP: 0.7869\n",
      "  SR-p53: 0.7459\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import PNAConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# ============================\n",
    "# Data Loading (ADD THIS)\n",
    "# ============================\n",
    "\n",
    "ASSAYS = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\",\n",
    "    \"NR-ER\", \"NR-ER-LBD\", \"NR-PPAR-gamma\", \n",
    "    \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---- Load graphs ----\n",
    "train_graphs = torch.load(\"graphs/train_2d.pt\")\n",
    "val_graphs   = torch.load(\"graphs/val_2d.pt\")\n",
    "test_graphs  = torch.load(\"graphs/test_2d.pt\")\n",
    "\n",
    "# ---- Load descriptors ----\n",
    "use_desc = True\n",
    "if use_desc:\n",
    "    train_desc = np.load(r\"E:\\graphml project\\novel\\processed\\train_rdkit_desc.npz\")[\"X\"]\n",
    "    val_desc   = np.load(r\"E:\\graphml project\\novel\\processed\\val_rdkit_desc.npz\")[\"X\"]\n",
    "    test_desc  = np.load(r\"E:\\graphml project\\novel\\processed\\test_rdkit_desc.npz\")[\"X\"]\n",
    "    desc_dim = train_desc.shape[1]\n",
    "else:\n",
    "    desc_dim = 32\n",
    "    train_desc = np.zeros((len(train_graphs), desc_dim), dtype=np.float32)\n",
    "    val_desc   = np.zeros((len(val_graphs), desc_dim), dtype=np.float32)\n",
    "    test_desc  = np.zeros((len(test_graphs), desc_dim), dtype=np.float32)\n",
    "\n",
    "# ---- Attach features ----\n",
    "def attach_features(graph_list, desc_array):\n",
    "    for i, g in enumerate(graph_list):\n",
    "        g.desc_features = torch.from_numpy(desc_array[i]).float()\n",
    "    return graph_list\n",
    "\n",
    "train_graphs = attach_features(train_graphs, train_desc)\n",
    "val_graphs   = attach_features(val_graphs, val_desc)\n",
    "test_graphs  = attach_features(test_graphs, test_desc)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_graphs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ============================\n",
    "# Text Prompts Definition (ADD THIS)\n",
    "# ============================\n",
    "\n",
    "ASSAY_DESCRIPTIONS = {\n",
    "    \"NR-AR\": \"androgen receptor binding and endocrine disruption potential\",\n",
    "    \"NR-AR-LBD\": \"androgen receptor ligand binding domain interaction\", \n",
    "    \"NR-AhR\": \"aryl hydrocarbon receptor activation and xenobiotic metabolism\",\n",
    "    \"NR-Aromatase\": \"aromatase enzyme inhibition and steroid metabolism\",\n",
    "    \"NR-ER\": \"estrogen receptor binding and hormonal activity\",\n",
    "    \"NR-ER-LBD\": \"estrogen receptor ligand binding domain interaction\",\n",
    "    \"NR-PPAR-gamma\": \"peroxisome proliferator-activated receptor gamma activation\",\n",
    "    \"SR-ARE\": \"antioxidant response element activation and oxidative stress\",\n",
    "    \"SR-ATAD5\": \"ATAD5 biomarker response and genotoxicity\",\n",
    "    \"SR-HSE\": \"heat shock response element activation and protein stress\",\n",
    "    \"SR-MMP\": \"mitochondrial membrane potential disruption and cytotoxicity\",\n",
    "    \"SR-p53\": \"p53 tumor suppressor pathway activation and DNA damage response\"\n",
    "}\n",
    "\n",
    "print(\"Assay Prompts:\")\n",
    "for assay, desc in ASSAY_DESCRIPTIONS.items():\n",
    "    print(f\"  {assay}: {desc}\")\n",
    "\n",
    "# ============================\n",
    "# PNA + Text Enhanced Model\n",
    "# ============================\n",
    "\n",
    "class PNAWithText(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks,\n",
    "                 hidden_dim=128, num_layers=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_tasks = n_tasks\n",
    "        self.desc_feature_dim = desc_feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # --- PNA Configuration ---\n",
    "        aggregators = ['mean', 'min', 'max', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "        \n",
    "        # Degree distribution for molecular graphs\n",
    "        self.deg = torch.tensor([0, 1, 2, 3, 4])\n",
    "        \n",
    "        # --- Feature Projections ---\n",
    "        self.node_proj = nn.Sequential(\n",
    "            nn.Linear(node_feature_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # --- PNA Layers ---\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            conv = PNAConv(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                aggregators=aggregators,\n",
    "                scalers=scalers,\n",
    "                deg=self.deg,\n",
    "                edge_dim=edge_feature_dim,\n",
    "                towers=1,\n",
    "                pre_layers=1,\n",
    "                post_layers=1\n",
    "            )\n",
    "            self.convs.append(conv)\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # --- Text Prompts ---\n",
    "        self.assay_prompts = nn.Parameter(torch.randn(n_tasks, 128))\n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # --- Cross-Attention Fusion ---\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=8,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # --- Enhanced Classifier ---\n",
    "        classifier_input_dim = hidden_dim * 2 + hidden_dim + desc_feature_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_tasks)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data, assay_attention=None):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # 1. Project node features\n",
    "        x = self.node_proj(x)\n",
    "        \n",
    "        # 2. PNA Message Passing\n",
    "        for i, (conv, bn) in enumerate(zip(self.convs, self.batch_norms)):\n",
    "            x_residual = x\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.elu(x)\n",
    "            \n",
    "            # Residual connection\n",
    "            if i % 2 == 1:\n",
    "                x = x + x_residual\n",
    "            \n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        # 3. Graph Readout\n",
    "        mean_pool = global_mean_pool(x, batch)\n",
    "        max_pool = global_max_pool(x, batch)\n",
    "        graph_features = torch.cat([mean_pool, max_pool], dim=1)\n",
    "        \n",
    "        # 4. Text Conditioning\n",
    "        if assay_attention is None:\n",
    "            assay_attention = torch.ones(len(graph_features), self.n_tasks, \n",
    "                                       device=graph_features.device) / self.n_tasks\n",
    "        \n",
    "        text_embeddings = torch.einsum('bi,ij->bj', assay_attention, self.assay_prompts)\n",
    "        text_features = self.text_proj(text_embeddings)\n",
    "        \n",
    "        # 5. Cross-Attention\n",
    "        text_as_query = text_features.unsqueeze(1)\n",
    "        graph_as_kv = graph_features[:, :self.hidden_dim].unsqueeze(1)\n",
    "        \n",
    "        attended_features, _ = self.cross_attention(\n",
    "            query=text_as_query,\n",
    "            key=graph_as_kv,\n",
    "            value=graph_as_kv\n",
    "        )\n",
    "        attended_features = attended_features.squeeze(1)\n",
    "        \n",
    "        # 6. Descriptor Features\n",
    "        desc_features = data.desc_features.view(len(graph_features), -1)\n",
    "        \n",
    "        # 7. Final Fusion\n",
    "        combined_features = torch.cat([graph_features, attended_features, desc_features], dim=1)\n",
    "        logits = self.classifier(combined_features)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# ============================\n",
    "# Training Functions\n",
    "# ============================\n",
    "\n",
    "def train_pna_epoch(loader, model, optimizer, criterion, device, n_tasks):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_graphs = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        B = batch.num_graphs\n",
    "        \n",
    "        # Smart assay attention\n",
    "        y_batch = batch.y.float().view(B, n_tasks)\n",
    "        w_batch = batch.weight.float().view(B, n_tasks)\n",
    "        labeled_mask = (w_batch > 0).float()\n",
    "        \n",
    "        if labeled_mask.sum() > 0:\n",
    "            assay_attention = labeled_mask / labeled_mask.sum(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "        else:\n",
    "            assay_attention = torch.ones(B, n_tasks, device=device) / n_tasks\n",
    "        \n",
    "        logits = model(batch, assay_attention)\n",
    "\n",
    "        # Loss computation\n",
    "        y = batch.y.float().view(-1, n_tasks)\n",
    "        w = batch.weight.float().view(-1, n_tasks)\n",
    "        \n",
    "        loss_unreduced = criterion(logits, y)\n",
    "        mask = (w > 0).float()\n",
    "        loss = (loss_unreduced * mask).sum() / mask.sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        total_graphs += B\n",
    "\n",
    "    return total_loss / total_graphs\n",
    "\n",
    "def evaluate(loader, model, device, assays):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    all_weights = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            B = batch.num_graphs\n",
    "            \n",
    "            assay_attention = torch.ones(B, len(assays), device=device) / len(assays)\n",
    "            \n",
    "            logits = model(batch, assay_attention)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            y = batch.y.float().view(-1, len(assays))\n",
    "            w = batch.weight.float().view(-1, len(assays))\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "            all_weights.append(w.cpu())\n",
    "\n",
    "    probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    labels = torch.cat(all_labels, dim=0).numpy()\n",
    "    weights = torch.cat(all_weights, dim=0).numpy()\n",
    "\n",
    "    roc_scores = {}\n",
    "    pr_scores = {}\n",
    "\n",
    "    for j, assay in enumerate(assays):\n",
    "        mask = weights[:, j] > 0\n",
    "        if mask.sum() < 5:\n",
    "            roc_scores[assay] = np.nan\n",
    "            pr_scores[assay] = np.nan\n",
    "            continue\n",
    "\n",
    "        y_true = labels[mask, j]\n",
    "        y_pred = probs[mask, j]\n",
    "\n",
    "        try:\n",
    "            roc_scores[assay] = roc_auc_score(y_true, y_pred)\n",
    "            pr_scores[assay] = average_precision_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            roc_scores[assay] = np.nan\n",
    "            pr_scores[assay] = np.nan\n",
    "\n",
    "    mean_roc = np.nanmean(list(roc_scores.values()))\n",
    "    mean_pr = np.nanmean(list(pr_scores.values()))\n",
    "    return roc_scores, pr_scores, mean_roc, mean_pr\n",
    "\n",
    "# ============================\n",
    "# Main Execution\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    EPOCHS = 100\n",
    "    LR = 2e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    sample = train_graphs[0]\n",
    "    node_dim = sample.x.size(1)\n",
    "    edge_dim = sample.edge_attr.size(1)\n",
    "    \n",
    "    print(f\"Node features: {node_dim}\")\n",
    "    print(f\"Edge features: {edge_dim}\")\n",
    "    print(f\"Descriptor features: {desc_dim}\")\n",
    "    print(f\"Number of tasks: {len(ASSAYS)}\")\n",
    "    \n",
    "    model = PNAWithText(\n",
    "        node_feature_dim=node_dim,\n",
    "        edge_feature_dim=edge_dim,\n",
    "        desc_feature_dim=desc_dim,\n",
    "        n_tasks=len(ASSAYS),\n",
    "        hidden_dim=128,\n",
    "        num_layers=4\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"PNA Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=LR, \n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_roc = -1.0\n",
    "    print(\"\\nStarting PNA Training...\")\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss = train_pna_epoch(train_loader, model, optimizer, criterion, device, len(ASSAYS))\n",
    "        roc_val, pr_val, mean_roc_val, mean_pr_val = evaluate(val_loader, model, device, ASSAYS)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch:03d} | Loss: {train_loss:.4f} | Val ROC: {mean_roc_val:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        \n",
    "        if mean_roc_val > best_val_roc:\n",
    "            best_val_roc = mean_roc_val\n",
    "            torch.save(model.state_dict(), \"pna_text_best.pt\")\n",
    "            print(f\"  → New best! (ROC: {best_val_roc:.4f})\")\n",
    "    \n",
    "    # Final test\n",
    "    model.load_state_dict(torch.load(\"pna_text_best.pt\"))\n",
    "    roc_test, pr_test, mean_roc_test, mean_pr_test = evaluate(test_loader, model, device, ASSAYS)\n",
    "    \n",
    "    print(f\"\\n🎯 FINAL PNA TEST RESULTS:\")\n",
    "    print(f\"ROC-AUC: {mean_roc_test:.4f}\")\n",
    "    print(f\"PR-AUC: {mean_pr_test:.4f}\")\n",
    "    \n",
    "    # Show per-assay results\n",
    "    print(\"\\nPer-assay ROC-AUC:\")\n",
    "    for assay in ASSAYS:\n",
    "        print(f\"  {assay}: {roc_test[assay]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57c285",
   "metadata": {},
   "source": [
    "***gt plus gnn***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec479586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "🔬 REAL TEXT PROMPTS BEING USED:\n",
      "   NR-AR: androgen receptor binding activity and endocrine disruption potential\n",
      "   NR-AR-LBD: androgen receptor ligand binding domain interaction and binding affinity\n",
      "   NR-AhR: aryl hydrocarbon receptor activation and xenobiotic metabolism pathway\n",
      "   NR-Aromatase: aromatase enzyme inhibition and steroid hormone metabolism\n",
      "   NR-ER: estrogen receptor binding and hormonal activity assessment\n",
      "   NR-ER-LBD: estrogen receptor ligand binding domain interaction specificity\n",
      "   NR-PPAR-gamma: peroxisome proliferator-activated receptor gamma activation\n",
      "   SR-ARE: antioxidant response element activation and oxidative stress response\n",
      "   SR-ATAD5: ATAD5 biomarker response and DNA damage genotoxicity\n",
      "   SR-HSE: heat shock response element activation and protein stress response\n",
      "   SR-MMP: mitochondrial membrane potential disruption and cytotoxicity\n",
      "   SR-p53: p53 tumor suppressor pathway activation and DNA damage response\n",
      "\n",
      "✅ Model initialized with REAL text prompts for 12 assays\n",
      "   GNN prompts shape: torch.Size([12, 128])\n",
      "   Transformer prompts shape: torch.Size([12, 128])\n",
      "\n",
      "📝 Sample prompt values (first 5 dimensions):\n",
      "   NR-AR: [ 0.02023736 -0.12419361 -0.1752163  -0.03329556 -0.00965503]\n",
      "   NR-AR-LBD: [-0.01760251 -0.03080538 -0.0765891   0.02836252 -0.20208506]\n",
      "   NR-AhR: [-0.14001745  0.00600112 -0.16309099  0.11940652 -0.08481558]\n",
      "   NR-Aromatase: [ 0.00095023  0.02529611 -0.08265778 -0.00598389 -0.03688869]\n",
      "   NR-ER: [-0.08613034  0.06590447 -0.04408365  0.02110245 -0.00100315]\n",
      "   NR-ER-LBD: [-0.04031619 -0.14424144  0.12906961 -0.06880806  0.07983688]\n",
      "   NR-PPAR-gamma: [-0.02982038 -0.18817462 -0.08609536 -0.06342715  0.10201889]\n",
      "   SR-ARE: [ 0.02341809 -0.1504132   0.03664639  0.07217935  0.17157698]\n",
      "   SR-ATAD5: [-0.03254435 -0.00678543 -0.07288717 -0.08645603  0.13761787]\n",
      "   SR-HSE: [-0.06111347 -0.02013475  0.0063789   0.12783553 -0.04845274]\n",
      "   SR-MMP: [-0.04798602  0.04343833  0.02393655 -0.05012726  0.10424081]\n",
      "   SR-p53: [-0.07313149 -0.03302258 -0.02593352  0.08715241  0.03772856]\n",
      "\n",
      "🚀 Starting training with real text prompts...\n",
      "Epoch  10 | Loss: 10.9910 | Fusion: GNN:0.46/TR:0.54\n",
      "Epoch  20 | Loss: 10.2251 | Fusion: GNN:0.45/TR:0.55\n",
      "Epoch  30 | Loss: 9.8004 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  40 | Loss: 9.5145 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  50 | Loss: 9.3020 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  60 | Loss: 9.0907 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  70 | Loss: 8.7657 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  80 | Loss: 8.6206 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch  90 | Loss: 8.5266 | Fusion: GNN:0.44/TR:0.56\n",
      "Epoch 100 | Loss: 8.2776 | Fusion: GNN:0.44/TR:0.56\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_max_pool\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# REAL TEXT PROMPTS FOR TOX21 ASSAYS\n",
    "# ============================\n",
    "\n",
    "ASSAY_DESCRIPTIONS = {\n",
    "    \"NR-AR\": \"androgen receptor binding activity and endocrine disruption potential\",\n",
    "    \"NR-AR-LBD\": \"androgen receptor ligand binding domain interaction and binding affinity\", \n",
    "    \"NR-AhR\": \"aryl hydrocarbon receptor activation and xenobiotic metabolism pathway\",\n",
    "    \"NR-Aromatase\": \"aromatase enzyme inhibition and steroid hormone metabolism\",\n",
    "    \"NR-ER\": \"estrogen receptor binding and hormonal activity assessment\",\n",
    "    \"NR-ER-LBD\": \"estrogen receptor ligand binding domain interaction specificity\",\n",
    "    \"NR-PPAR-gamma\": \"peroxisome proliferator-activated receptor gamma activation\",\n",
    "    \"SR-ARE\": \"antioxidant response element activation and oxidative stress response\",\n",
    "    \"SR-ATAD5\": \"ATAD5 biomarker response and DNA damage genotoxicity\",\n",
    "    \"SR-HSE\": \"heat shock response element activation and protein stress response\",\n",
    "    \"SR-MMP\": \"mitochondrial membrane potential disruption and cytotoxicity\",\n",
    "    \"SR-p53\": \"p53 tumor suppressor pathway activation and DNA damage response\"\n",
    "}\n",
    "\n",
    "# Convert to embedding initialization\n",
    "def initialize_prompts_from_descriptions(descriptions_dict, assays_list, embedding_dim=128):\n",
    "    \"\"\"Initialize prompts using text descriptions\"\"\"\n",
    "    prompts = []\n",
    "    \n",
    "    for assay in assays_list:\n",
    "        description = descriptions_dict[assay]\n",
    "        # Simple hash-based initialization\n",
    "        hash_val = hash(description) % 10000\n",
    "        torch.manual_seed(hash_val)\n",
    "        prompt = torch.randn(embedding_dim) * 0.1\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return torch.stack(prompts)\n",
    "\n",
    "# ============================\n",
    "# Enhanced GNN Branch WITH REAL PROMPTS\n",
    "# ============================\n",
    "\n",
    "class EnhancedGNNBranch(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks,\n",
    "                 hidden_dim=128, num_layers=4, dropout=0.2, assay_descriptions=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_tasks = n_tasks\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Node projection\n",
    "        self.node_proj = nn.Sequential(\n",
    "            nn.Linear(node_feature_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # GINE layers\n",
    "        self.gnn_layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            nn_mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            conv = GINEConv(nn_mlp, edge_dim=edge_feature_dim)\n",
    "            self.gnn_layers.append(conv)\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # REAL TEXT PROMPTS INITIALIZATION\n",
    "        if assay_descriptions:\n",
    "            initial_prompts = initialize_prompts_from_descriptions(\n",
    "                assay_descriptions, \n",
    "                list(assay_descriptions.keys())\n",
    "            )\n",
    "            self.assay_prompts = nn.Parameter(initial_prompts)\n",
    "        else:\n",
    "            self.assay_prompts = nn.Parameter(torch.randn(n_tasks, 128))\n",
    "        \n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Cross-attention\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads=8, dropout=0.1, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output_proj = nn.Linear(hidden_dim * 2 + hidden_dim + desc_feature_dim, n_tasks)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, -1.0)\n",
    "    \n",
    "    def forward(self, data, assay_attention=None):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        B = data.num_graphs\n",
    "        \n",
    "        # 1. GNN Processing\n",
    "        x = self.node_proj(x)\n",
    "        \n",
    "        for i, (conv, bn) in enumerate(zip(self.gnn_layers, self.batch_norms)):\n",
    "            x_res = x\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.elu(x)\n",
    "            if i % 2 == 1:\n",
    "                x = x + x_res\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        # 2. Graph Readout\n",
    "        mean_pool = global_mean_pool(x, batch)\n",
    "        max_pool = global_max_pool(x, batch)\n",
    "        graph_features = torch.cat([mean_pool, max_pool], dim=1)\n",
    "        \n",
    "        # 3. TEXT PROMPT CONDITIONING\n",
    "        if assay_attention is None:\n",
    "            assay_attention = torch.ones(B, self.n_tasks, device=graph_features.device) / self.n_tasks\n",
    "        \n",
    "        text_emb = torch.einsum('bi,ij->bj', assay_attention, self.assay_prompts)\n",
    "        text_features = self.text_proj(text_emb)\n",
    "        \n",
    "        # 4. Cross-Attention\n",
    "        text_as_query = text_features.unsqueeze(1)\n",
    "        graph_as_kv = graph_features[:, :self.hidden_dim].unsqueeze(1)\n",
    "        attended, _ = self.cross_attention(text_as_query, graph_as_kv, graph_as_kv)\n",
    "        attended_features = attended.squeeze(1)\n",
    "        \n",
    "        # 5. Fusion\n",
    "        desc_features = data.desc_features.view(B, -1)\n",
    "        combined = torch.cat([graph_features, attended_features, desc_features], dim=1)\n",
    "        \n",
    "        return self.output_proj(combined)\n",
    "\n",
    "# ============================\n",
    "# Enhanced Transformer Branch WITH REAL PROMPTS\n",
    "# ============================\n",
    "\n",
    "class MolecularGraphTransformer(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks,\n",
    "                 hidden_dim=128, num_layers=4, num_heads=8, dropout=0.1, assay_descriptions=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_tasks = n_tasks\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Feature projections\n",
    "        self.node_proj = nn.Linear(node_feature_dim, hidden_dim)\n",
    "        \n",
    "        # CLS token\n",
    "        self.cls_token = nn.Parameter(torch.randn(hidden_dim))\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(hidden_dim, num_heads, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # REAL TEXT PROMPTS INITIALIZATION\n",
    "        if assay_descriptions:\n",
    "            initial_prompts = initialize_prompts_from_descriptions(\n",
    "                assay_descriptions,\n",
    "                list(assay_descriptions.keys())\n",
    "            )\n",
    "            self.assay_prompts = nn.Parameter(initial_prompts)\n",
    "        else:\n",
    "            self.assay_prompts = nn.Parameter(torch.randn(n_tasks, 128))\n",
    "        \n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Multi-modal fusion\n",
    "        self.fusion_attention = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads=8, dropout=0.1, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output_proj = nn.Linear(hidden_dim + hidden_dim + desc_feature_dim, n_tasks)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.cls_token, std=0.02)\n",
    "    \n",
    "    def forward(self, data, assay_attention=None):\n",
    "        x, batch = data.x, data.batch\n",
    "        B = data.num_graphs\n",
    "        \n",
    "        # 1. Project node features\n",
    "        node_features = self.node_proj(x)\n",
    "        \n",
    "        # 2. Process each graph with transformer\n",
    "        graph_representations = []\n",
    "        unique_batches = torch.unique(batch)\n",
    "        \n",
    "        for graph_idx in unique_batches:\n",
    "            graph_mask = (batch == graph_idx)\n",
    "            graph_nodes = node_features[graph_mask]\n",
    "            \n",
    "            # Add CLS token\n",
    "            cls_tokens = self.cls_token.unsqueeze(0)\n",
    "            sequence = torch.cat([cls_tokens, graph_nodes], dim=0)\n",
    "            \n",
    "            # Transformer processing\n",
    "            for transformer_layer in self.transformer_layers:\n",
    "                sequence = transformer_layer(sequence)\n",
    "            \n",
    "            graph_rep = sequence[0]\n",
    "            graph_representations.append(graph_rep)\n",
    "        \n",
    "        graph_features = torch.stack(graph_representations)\n",
    "        \n",
    "        # 3. TEXT PROMPT CONDITIONING\n",
    "        if assay_attention is None:\n",
    "            assay_attention = torch.ones(B, self.n_tasks, device=graph_features.device) / self.n_tasks\n",
    "        \n",
    "        text_emb = torch.einsum('bi,ij->bj', assay_attention, self.assay_prompts)\n",
    "        text_features = self.text_proj(text_emb)\n",
    "        \n",
    "        # 4. Multi-modal fusion\n",
    "        graph_as_query = graph_features.unsqueeze(1)\n",
    "        text_as_kv = text_features.unsqueeze(1)\n",
    "        fused, _ = self.fusion_attention(graph_as_query, text_as_kv, text_as_kv)\n",
    "        fused_features = fused.squeeze(1)\n",
    "        \n",
    "        # 5. Final fusion\n",
    "        desc_features = data.desc_features.view(B, -1)\n",
    "        combined = torch.cat([graph_features, fused_features, desc_features], dim=1)\n",
    "        \n",
    "        return self.output_proj(combined)\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attention(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_out))\n",
    "        return x\n",
    "\n",
    "# ============================\n",
    "# Hybrid Model WITH REAL PROMPTS\n",
    "# ============================\n",
    "\n",
    "class HybridTextGraphModel(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks, assay_descriptions):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_tasks = n_tasks\n",
    "        \n",
    "        # Two branches with REAL PROMPTS\n",
    "        self.gnn_branch = EnhancedGNNBranch(\n",
    "            node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks,\n",
    "            assay_descriptions=assay_descriptions\n",
    "        )\n",
    "        \n",
    "        self.transformer_branch = MolecularGraphTransformer(\n",
    "            node_feature_dim, edge_feature_dim, desc_feature_dim, n_tasks,\n",
    "            assay_descriptions=assay_descriptions\n",
    "        )\n",
    "        \n",
    "        # Learnable fusion\n",
    "        self.fusion_weights = nn.Parameter(torch.ones(2))\n",
    "        self.task_gates = nn.Parameter(torch.ones(n_tasks, 2))\n",
    "    \n",
    "    def forward(self, data, assay_attention=None):\n",
    "        gnn_logits = self.gnn_branch(data, assay_attention)\n",
    "        transformer_logits = self.transformer_branch(data, assay_attention)\n",
    "        \n",
    "        global_weights = F.softmax(self.fusion_weights, dim=0)\n",
    "        task_weights = F.softmax(self.task_gates, dim=1)\n",
    "        \n",
    "        global_weights_expanded = global_weights.unsqueeze(0).unsqueeze(0)\n",
    "        task_weights_expanded = task_weights.unsqueeze(0)\n",
    "        \n",
    "        combined_weights = global_weights_expanded * task_weights_expanded\n",
    "        logits_stacked = torch.stack([gnn_logits, transformer_logits], dim=-1)\n",
    "        fused_logits = (logits_stacked * combined_weights).sum(dim=-1)\n",
    "        \n",
    "        return fused_logits, gnn_logits, transformer_logits, global_weights\n",
    "\n",
    "# ============================\n",
    "# Training Pipeline\n",
    "# ============================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.75, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, logits, targets, weights=None):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        \n",
    "        if weights is not None:\n",
    "            focal_loss = focal_loss * weights\n",
    "            \n",
    "        if weights is not None and weights.sum() > 0:\n",
    "            return focal_loss.sum() / weights.sum()\n",
    "        return focal_loss.mean()\n",
    "\n",
    "def main():\n",
    "    ASSAYS = [\n",
    "        \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\",\n",
    "        \"NR-ER\", \"NR-ER-LBD\", \"NR-PPAR-gamma\",\n",
    "        \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "    ]\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print the REAL prompts we're using\n",
    "    print(\" REAL TEXT PROMPTS BEING USED:\")\n",
    "    for assay, desc in ASSAY_DESCRIPTIONS.items():\n",
    "        print(f\"   {assay}: {desc}\")\n",
    "    \n",
    "    # FIXED: Pass assay_descriptions argument\n",
    "    sample = train_graphs[0]\n",
    "    model = HybridTextGraphModel(\n",
    "        node_feature_dim=sample.x.size(1),\n",
    "        edge_feature_dim=sample.edge_attr.size(1),\n",
    "        desc_feature_dim=desc_dim,\n",
    "        n_tasks=len(ASSAYS),\n",
    "        assay_descriptions=ASSAY_DESCRIPTIONS  # THIS WAS MISSING!\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\n Model initialized with REAL text prompts for {len(ASSAYS)} assays\")\n",
    "    print(f\"   GNN prompts shape: {model.gnn_branch.assay_prompts.shape}\")\n",
    "    print(f\"   Transformer prompts shape: {model.transformer_branch.assay_prompts.shape}\")\n",
    "    \n",
    "    # Show prompt values\n",
    "    print(f\"\\n Sample prompt values (first 5 dimensions):\")\n",
    "    for i, assay in enumerate(ASSAYS):\n",
    "        prompt_vals = model.gnn_branch.assay_prompts[i][:5].detach().cpu().numpy()\n",
    "        print(f\"   {assay}: {prompt_vals}\")\n",
    "    \n",
    "    # Training setup\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "    criterion = FocalLoss(alpha=0.75, gamma=2.0)\n",
    "    \n",
    "    print(\"\\n Starting training with real text prompts...\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, 101):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            B = batch.num_graphs\n",
    "            \n",
    "            # Smart assay attention\n",
    "            y_batch = batch.y.float().view(B, len(ASSAYS))\n",
    "            w_batch = batch.weight.float().view(B, len(ASSAYS))\n",
    "            labeled_mask = (w_batch > 0).float()\n",
    "            \n",
    "            if labeled_mask.sum() > 0:\n",
    "                assay_attention = labeled_mask / labeled_mask.sum(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "            else:\n",
    "                assay_attention = torch.ones(B, len(ASSAYS), device=device) / len(ASSAYS)\n",
    "            \n",
    "            # Forward pass with REAL prompts\n",
    "            fused_logits, gnn_logits, transformer_logits, fusion_weights = model(batch, assay_attention)\n",
    "            \n",
    "            # Loss\n",
    "            y = batch.y.float().view(-1, len(ASSAYS))\n",
    "            w = batch.weight.float().view(-1, len(ASSAYS))\n",
    "            loss = criterion(fused_logits, y, w)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            gnn_w, tr_w = fusion_weights[0].item(), fusion_weights[1].item()\n",
    "            print(f\"Epoch {epoch:3d} | Loss: {total_loss:.4f} | Fusion: GNN:{gnn_w:.2f}/TR:{tr_w:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8490f52",
   "metadata": {},
   "source": [
    "***3 d feature extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ac001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c3a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tox21_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
